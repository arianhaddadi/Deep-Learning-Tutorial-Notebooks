{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Different categories of RNN models:\n",
        "\n",
        " - Many-to-one (sentiment analysis, fake news detection)\n",
        " - many-to-many (i.e. seq2seq, machine translation, text summary)\n",
        " - one-to-many (image captioning), one-to-one (plain MLP networks)\n",
        " \n",
        "\n",
        "We previously looked at a many-to-one model for a sentiment analysis task (the IMDB dataset), and now let's dive into a more complicated type of RNN: many-to-many, i.e. seq2seq."
      ],
      "metadata": {
        "id": "1M0jlU56kXaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages and download data\n",
        "\n",
        "Dataset introduction: \n",
        "\n",
        "This [dataset](https://www.manythings.org/anki/) consists of many combinations of bilingual sentence pairs. The lengths of the sentences and the vocabulary sizes are relatively small. In this notebook, we choose the subset of English-French sentence pairs. \n",
        "\n",
        "Main steps of notebook include:\n",
        " - Preprocess raw text data (regex data cleaning, deciding max lengths, tokenizer training)\n",
        " - Model setup for training (using keras functional API instead of sequential API)\n",
        " - Model setup for predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "1tGMb5p-Y0u5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fsg4Y-jyEMm_"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import time\n",
        "import os \n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed_everything(940)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and extract text data\n",
        "text_file = keras.utils.get_file(\n",
        "    fname=\"fra-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# location of downloaded data\n",
        "print('location of downloaded data: ',text_file)\n",
        "\n",
        "# change data path to a pathlib object for parsing\n",
        "text_file = pathlib.Path(text_file).parent / \"fra.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2xOf8YCEOgk",
        "outputId": "df34b909-0df2-4d4b-ba40-91c6fe3871a2"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "location of downloaded data:  /root/.keras/datasets/fra-eng.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess raw text data\n",
        "\n",
        "In this section, we will perform standard text preprocessing such as lowercasing characters, removing miscellaneous symbols, standardize whitespace symbols. A majority of the work is done using the regular expression library of python. Then we will train a tokenizer from scratch.  "
      ],
      "metadata": {
        "id": "ptSeNDIyY7bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RegEx preprocessing"
      ],
      "metadata": {
        "id": "MijRuU57ZsIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_file,'r',encoding='utf-8') as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "# list for storing parsed data\n",
        "text_pairs = []\n",
        "\n",
        "for line in lines:\n",
        "    # split source & target sentence\n",
        "    eng, fra = line.split(\"\\t\")\n",
        "\n",
        "    # store the parsed datapoint\n",
        "    text_pairs.append((eng,fra))\n",
        "\n",
        "del lines"
      ],
      "metadata": {
        "id": "4ge7CAGxEWlX"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(s,verbose=False):\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # convert characters to lowercase\n",
        "    # convert characters to ascii for regex preprocessing\n",
        "    s = unicode_to_ascii(s.lower())\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # Remove the characters - <>()|&©ø\"',;?~*!\n",
        "    s = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove punctuations at the end of a word\n",
        "    s = re.sub(\"(\\.\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\-\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\:\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\!\\s+)\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove other characters that are not letters \n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove multiple whitespaces\n",
        "    s = re.sub(r'(\\s+)', r' ', s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # Remove the single character hanging between any two spaces\n",
        "    s = re.sub(\"(\\s+.\\s+)\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # removes whitespaces in the beginning and the end\n",
        "    s = s.strip()\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # add start and end of sentence tokens\n",
        "    s = '<start>' +' '+ s +' '+'<end>'\n",
        "    return s\n",
        "\n",
        "s = '  1234 reguLAR eXpreSSion sooo\\t hard!!! - <>()|&©ø\"\\',;?~*   '\n",
        "preprocess_sentence(s,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Eanr_id8KiAh",
        "outputId": "218693c8-e5b1-4c1e-81e1-29df87bace84"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1234 reguLAR eXpreSSion sooo\t hard!!! - <>()|&©ø\"',;?~*   \n",
            "  1234 regular expression sooo\t hard!!! - <>()|&©ø\"',;?~*   \n",
            "  1234 regular expression sooo\t hard    -                   \n",
            "  1234 regular expression sooo\t hard     \n",
            " regular expression sooo hard \n",
            " regular expression sooo hard \n",
            " regular expression sooo hard \n",
            "regular expression sooo hard\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> regular expression sooo hard <end>'"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean raw text using regex"
      ],
      "metadata": {
        "id": "YSfn7Qaj38k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#text_pairs = text_pairs[:5000]\n",
        "\n",
        "# lists to store preprocessed text\n",
        "lang_eng = []\n",
        "lang_fra = []\n",
        "\n",
        "# separate english and french text\n",
        "raw_data_eng, raw_data_fra = list(zip(*text_pairs))\n",
        "raw_data_eng, raw_data_fra = list(raw_data_eng), list(raw_data_fra)\n",
        "\n",
        "# preprocess english and french raw text\n",
        "for i, j in zip(raw_data_eng, raw_data_fra):\n",
        "    preprocessed_data_eng = preprocess_sentence(i)\n",
        "    preprocessed_data_fra = preprocess_sentence(j)\n",
        "    lang_eng.append(preprocessed_data_eng)\n",
        "    lang_fra.append(preprocessed_data_fra)\n",
        "\n",
        "del raw_data_eng; del raw_data_fra;\n",
        "# del text_pairs; "
      ],
      "metadata": {
        "id": "DnIkqmzi18GJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_eng[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P9GVyRH_YkF",
        "outputId": "fabc4039-a950-4495-f5e7-98b778dc68bc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> go. <end>',\n",
              " '<start> hi. <end>',\n",
              " '<start> run <end>',\n",
              " '<start> run <end>',\n",
              " '<start> who <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_fra[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgZtOhZ_jfu",
        "outputId": "268959bc-a91c-4577-8b8a-7650b7c89c44"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> va <end>',\n",
              " '<start> salut <end>',\n",
              " '<start> cours <end>',\n",
              " '<start> courez <end>',\n",
              " '<start> qui <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select sentences that are shorter than the maximum lengths allowed\n",
        "\n",
        "In a large dataset, it is possible that a very few sentences are very lengthy, while the remaining majority are much shorter. In this case, if we keep those lengthy sentences, then we need to zero pad the remaining ones up to the same length, which requires the machine to store a lot of zeros for nothing. To avoid this, we simply look at the distribution of lengths for both languages, and regulate the max lengths. "
      ],
      "metadata": {
        "id": "4Gs9sQoC42Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count lengths of sentences in english and french\n",
        "eng_lengths = np.array([len(sentence.split()) for sentence in lang_eng])\n",
        "fra_lengths = np.array([len(sentence.split()) for sentence in lang_fra])"
      ],
      "metadata": {
        "id": "2EELv4qD2SW_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(eng_lengths,bins=np.arange(0,60,5),density=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Af25QPHR3AHH",
        "outputId": "3fa0f525-0df1-4c89-e39f-6b950bf394c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAS8klEQVR4nO3df6zd913f8ecLuw5dO5LWvVTMP2ZXMWK3Ksvgxi1am3WJWuyVxUw4zG4nkimSQWCJCSrmMintDEjNfjRMqifVW7KGdJljBQrW4s3NmkqdUAm+SUPCjTHcGhPbdOQ2SQMZSoOT9/44X29np9e5X/v+sO/Hz4d0db/fz+fzPef9kY9f56vP95zvTVUhSWrXd1zqAiRJi8ugl6TGGfSS1DiDXpIaZ9BLUuMMeklqXK+gT7IlyfEk00n2zNJ/Q5LHk5xNsn2kb32SLyQ5luTpJBsWpnRJUh9zBn2SFcA+YCswDuxMMj4y7BngNuD+WR7i14B/XVV/C9gMPDufgiVJF2ZljzGbgemqOgGQ5ACwDXj63ICqOtn1vTZ8YPeGsLKqHu7GvTTXk73tbW+rDRs29CxfkgTw2GOPfaOqxmbr6xP0a4BTQ/ungXf3fO7vBb6Z5DeAjcD/APZU1avDg5LsAnYBrF+/nsnJyZ4PL0kCSPIn5+tb7IuxK4H3AR8FrgfewWCJ5/9TVfuraqKqJsbGZn1DkiRdpD5BfwZYN7S/tmvr4zTwRFWdqKqzwG8CP3BhJUqS5qNP0B8FNiXZmGQVsAM41PPxjwLXJDl3mn4jQ2v7kqTFN2fQd2fiu4EjwDHgYFVNJdmb5GaAJNcnOQ3cAnwmyVR37KsMlm2+mOQpIMB/WJypSJJmk8vtNsUTExPlxVhJujBJHquqidn6/GasJDXOoJekxhn0ktQ4g16SGtfnm7E6jw17HlrS5zv5yQ8t6fNJaoNn9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3rFfRJtiQ5nmQ6yZ5Z+m9I8niSs0m2z9L/XUlOJ/n0QhQtSepvzqBPsgLYB2wFxoGdScZHhj0D3Abcf56H+SXgyxdfpiTpYvU5o98MTFfViap6BTgAbBseUFUnq+pJ4LXRg5P8IPB24AsLUK8k6QL1Cfo1wKmh/dNd25ySfAfwb4GPzjFuV5LJJJMzMzN9HlqS1NNiX4z9aeBwVZ1+vUFVtb+qJqpqYmxsbJFLkqQrS58/JXgGWDe0v7Zr6+OHgPcl+WngzcCqJC9V1bdd0JUkLY4+QX8U2JRkI4OA3wF8uM+DV9VHzm0nuQ2YMOQlaWnNuXRTVWeB3cAR4BhwsKqmkuxNcjNAkuuTnAZuAT6TZGoxi5Yk9dfnjJ6qOgwcHmm7Y2j7KIMlndd7jM8Cn73gCiVJ8+I3YyWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNa5X0CfZkuR4kukk3/bHvZPckOTxJGeTbB9qvy7JV5JMJXkyyT9eyOIlSXObM+iTrAD2AVuBcWBnkvGRYc8AtwH3j7T/JfATVfVOYAvwq0mumW/RkqT++vxx8M3AdFWdAEhyANgGPH1uQFWd7PpeGz6wqv5waPtPkzwLjAHfnHflkqRe+izdrAFODe2f7touSJLNwCrga7P07UoymWRyZmbmQh9akvQ6luRibJLvAe4D/mlVvTbaX1X7q2qiqibGxsaWoiRJumL0CfozwLqh/bVdWy9Jvgt4CPgXVfU7F1aeJGm++gT9UWBTko1JVgE7gEN9Hrwb/3ng16rqwYsvU5J0seYM+qo6C+wGjgDHgINVNZVkb5KbAZJcn+Q0cAvwmSRT3eE/DtwA3Jbkie7nukWZiSRpVn0+dUNVHQYOj7TdMbR9lMGSzuhxnwM+N88aJUnz4DdjJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1rlfQJ9mS5HiS6SR7Zum/IcnjSc4m2T7Sd2uSP+p+bl2owiVJ/cwZ9ElWAPuArcA4sDPJ+MiwZ4DbgPtHjn0r8HHg3cBm4ONJ3jL/siVJffU5o98MTFfViap6BTgAbBseUFUnq+pJ4LWRY38YeLiqnq+qF4CHgS0LULckqac+Qb8GODW0f7pr66PXsUl2JZlMMjkzM9PzoSVJfVwWF2Oran9VTVTVxNjY2KUuR5Ka0ifozwDrhvbXdm19zOdYSdIC6BP0R4FNSTYmWQXsAA71fPwjwAeTvKW7CPvBrk2StETmDPqqOgvsZhDQx4CDVTWVZG+SmwGSXJ/kNHAL8JkkU92xzwO/xODN4iiwt2uTJC2RlX0GVdVh4PBI2x1D20cZLMvMduw9wD3zqFGSNA+XxcVYSdLiMeglqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcb2CPsmWJMeTTCfZM0v/VUke6PofTbKha39DknuTPJXkWJKPLWz5kqS5zBn0SVYA+4CtwDiwM8n4yLDbgReq6lrgLuDOrv0W4Kqqehfwg8BPnnsTkCQtjT5n9JuB6ao6UVWvAAeAbSNjtgH3dtsPAjclCVDAm5KsBN4IvAL8+YJULknqpU/QrwFODe2f7tpmHVNVZ4EXgdUMQv9/A18HngH+TVU9P8+aJUkXYLEvxm4GXgX+BrAR+Pkk7xgdlGRXkskkkzMzM4tckiRdWfoE/Rlg3dD+2q5t1jHdMs3VwHPAh4H/XlV/VVXPAr8NTIw+QVXtr6qJqpoYGxu78FlIks6rT9AfBTYl2ZhkFbADODQy5hBwa7e9HXikqorBcs2NAEneBLwH+IOFKFyS1M+cQd+tue8GjgDHgINVNZVkb5Kbu2F3A6uTTAM/B5z7COY+4M1Jphi8YfynqnpyoSchSTq/lX0GVdVh4PBI2x1D2y8z+Cjl6HEvzdYuSVo6fjNWkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJalyvoE+yJcnxJNNJ9szSf1WSB7r+R5NsGOr7/iRfSTKV5Kkk37lw5UuS5jJn0CdZAewDtgLjwM4k4yPDbgdeqKprgbuAO7tjVwKfA36qqt4JvB/4qwWrXpI0pz5n9JuB6ao6UVWvAAeAbSNjtgH3dtsPAjclCfBB4Mmq+j2Aqnquql5dmNIlSX30Cfo1wKmh/dNd26xjquos8CKwGvheoJIcSfJ4kl+Y7QmS7EoymWRyZmbmQucgSXodi30xdiXwXuAj3e9/lOSm0UFVtb+qJqpqYmxsbJFLkqQrS5+gPwOsG9pf27XNOqZbl78aeI7B2f+Xq+obVfWXwGHgB+ZbtCSpvz5BfxTYlGRjklXADuDQyJhDwK3d9nbgkaoq4AjwriR/rXsD+HvA0wtTuiSpj5VzDaiqs0l2MwjtFcA9VTWVZC8wWVWHgLuB+5JMA88zeDOgql5I8ikGbxYFHK6qhxZpLpKkWcwZ9ABVdZjBsstw2x1D2y8Dt5zn2M8x+IilJOkS8JuxktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa1yvok2xJcjzJdJI9s/RfleSBrv/RJBtG+tcneSnJRxembElSX3MGfZIVwD5gKzAO7EwyPjLsduCFqroWuAu4c6T/U8B/m3+5kqQL1eeMfjMwXVUnquoV4ACwbWTMNuDebvtB4KYkAUjyo8AfA1MLU7Ik6UKs7DFmDXBqaP808O7zjamqs0leBFYneRn458AHgPMu2yTZBewCWL9+fe/irzQb9jy0pM938pMfWtLnk7Q4Fvti7CeAu6rqpdcbVFX7q2qiqibGxsYWuSRJurL0OaM/A6wb2l/btc025nSSlcDVwHMMzvy3J/lXwDXAa0lerqpPz7tySVIvfYL+KLApyUYGgb4D+PDImEPArcBXgO3AI1VVwPvODUjyCeAlQ16SltacQd+tue8GjgArgHuqairJXmCyqg4BdwP3JZkGnmfwZiBJugz0OaOnqg4Dh0fa7hjafhm4ZY7H+MRF1CdJmie/GStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXG9gj7JliTHk0wn2TNL/1VJHuj6H02yoWv/QJLHkjzV/b5xYcuXJM1lzqBPsgLYB2wFxoGdScZHht0OvFBV1wJ3AXd27d8A/mFVvQu4FbhvoQqXJPXT54x+MzBdVSeq6hXgALBtZMw24N5u+0HgpiSpqq9W1Z927VPAG5NctRCFS5L66RP0a4BTQ/unu7ZZx1TVWeBFYPXImB8DHq+qb40+QZJdSSaTTM7MzPStXZLUw5JcjE3yTgbLOT85W39V7a+qiaqaGBsbW4qSJOmK0SfozwDrhvbXdm2zjkmyErgaeK7bXwt8HviJqvrafAuWJF2YPkF/FNiUZGOSVcAO4NDImEMMLrYCbAceqapKcg3wELCnqn57oYqWJPU3Z9B3a+67gSPAMeBgVU0l2Zvk5m7Y3cDqJNPAzwHnPoK5G7gWuCPJE93Pdy/4LCRJ57Wyz6CqOgwcHmm7Y2j7ZeCWWY77ZeCX51mjJGke/GasJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxvf7wyHKyYc9Dl7oESbqsNBf0WjhL+aZ58pMfWrLnkq40vZZukmxJcjzJdJI9s/RfleSBrv/RJBuG+j7WtR9P8sMLV7okqY85gz7JCmAfsBUYB3YmGR8ZdjvwQlVdC9wF3NkdOw7sAN4JbAH+ffd4kqQl0mfpZjMwXVUnAJIcALYBTw+N2QZ8ott+EPh0knTtB6rqW8AfJ5nuHu8rC1O+WrHU11ZcKtKVpE/QrwFODe2fBt59vjFVdTbJi8Dqrv13Ro5dM/oESXYBu7rdl5Ic71X97N4GfGMex1/OnNsCyZ1L9Uz/l/92y9NymtvfPF/HZXExtqr2A/sX4rGSTFbVxEI81uXGuS1fLc/PuV3++lyMPQOsG9pf27XNOibJSuBq4Lmex0qSFlGfoD8KbEqyMckqBhdXD42MOQTc2m1vBx6pqurad3SfytkIbAJ+d2FKlyT1MefSTbfmvhs4AqwA7qmqqSR7gcmqOgTcDdzXXWx9nsGbAd24gwwu3J4FfqaqXl2kuZyzIEtAlynntny1PD/ndpnL4MRbktQq73UjSY0z6CWpcc0E/Vy3aVhuktyT5Nkkvz/U9tYkDyf5o+73Wy5ljRcrybokX0rydJKpJD/btS/7+SX5ziS/m+T3urn9y659Y3d7kOnudiGrLnWtFyvJiiRfTfJfu/2W5nYyyVNJnkgy2bUt+9dlE0Hf8zYNy81nGdw2Ytge4ItVtQn4Yre/HJ0Ffr6qxoH3AD/T/Xu1ML9vATdW1d8GrgO2JHkPg9uC3NXdJuQFBrcNWa5+Fjg2tN/S3AD+flVdN/T5+WX/umwi6Bm6TUNVvQKcu03DslVVX2bwCaZh24B7u+17gR9d0qIWSFV9vaoe77b/gkForKGB+dXAS93uG7qfAm5kcHsQWKZzA0iyFvgQ8B+7/dDI3F7Hsn9dthL0s92m4dtutdCAt1fV17vt/wW8/VIWsxC6O53+HeBRGplft7TxBPAs8DDwNeCbVXW2G7KcX5+/CvwC8Fq3v5p25gaDN+UvJHmsuzULNPC6vCxugaALV1WVZFl/NjbJm4FfB/5ZVf354ORwYDnPr/uuyHVJrgE+D3zfJS5pQST5EeDZqnosyfsvdT2L5L1VdSbJdwMPJ/mD4c7l+rps5Yz+SrnVwp8l+R6A7vezl7iei5bkDQxC/j9X1W90zc3MD6Cqvgl8Cfgh4Jru9iCwfF+ffxe4OclJBsujNwL/jjbmBkBVnel+P8vgTXozDbwuWwn6PrdpaMHwrSZuBX7rEtZy0bp13buBY1X1qaGuZT+/JGPdmTxJ3gh8gME1iC8xuD0ILNO5VdXHqmptVW1g8H/skar6CA3MDSDJm5L89XPbwAeB36eF12Ur34xN8g8YrB+eu03Dr1zikuYlyX8B3s/gNql/Bnwc+E3gILAe+BPgx6tq9ILtZS/Je4H/CTzF/1vr/UUG6/TLen5Jvp/BBbsVDE6kDlbV3iTvYHAW/Fbgq8A/6f5Ow7LULd18tKp+pJW5dfP4fLe7Eri/qn4lyWqW++uylaCXJM2ulaUbSdJ5GPSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcf8HRuKQdBKqYoUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(fra_lengths,bins=np.arange(0,60,5),density=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "5jxkxZnJ3E3N",
        "outputId": "0ce3ca71-e5df-4216-c6d2-5a8c44c8412c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at the histograms, we can restrict the length of English sentences to 20, and the length of French sentences to 20"
      ],
      "metadata": {
        "id": "n1KxnB3G3_8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hard coded max lengths\n",
        "max_length_targ, max_length_inp = 20,20\n",
        "\n",
        "# put two lists into a df to select pairs\n",
        "cleaned_text = pd.DataFrame({'eng_cleaned':lang_eng,'fra_cleaned':lang_fra})\n",
        "\n",
        "# condition of a pair getting selected\n",
        "def select_sentence_pair(row):\n",
        "    # selected if both sentences are shorter than the max lengths\n",
        "    if len(row.iloc[0].split()) < max_length_inp and len(row.iloc[1].split()) < max_length_targ:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "keep = cleaned_text.apply(select_sentence_pair,axis=1)\n",
        "cleaned_text['keep'] = keep\n",
        "\n",
        "# filter out unwanted data \n",
        "cleaned_text = cleaned_text[cleaned_text.keep == 1]\n",
        "\n",
        "lang_eng = cleaned_text.iloc[:,0].tolist()\n",
        "lang_fra = cleaned_text.iloc[:,1].tolist()\n",
        "\n",
        "del cleaned_text"
      ],
      "metadata": {
        "id": "ieXNkQSV470x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Detect empty sentences\n",
        "\n",
        "If any empty sentence detected in a pair, then we will delete that pair from the data."
      ],
      "metadata": {
        "id": "IrqcbvmyE-2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# detect if there are any empty sentences,i.e, which only have '<start>' and '<end>' tokens\n",
        "ind = []\n",
        "\n",
        "# for each sentence in the corpus\n",
        "for i in range(len(lang_eng)):\n",
        "    \n",
        "    for j in lang_eng[i].split():\n",
        "        if j == '<start>':\n",
        "            empty = True\n",
        "        elif j == '<end>' and empty:\n",
        "            ind.append(i)\n",
        "            print('empty English sentence detected! index:',i)\n",
        "        else: \n",
        "            empty = False\n",
        "    \n",
        "print('# of empty English sentences:', len(ind))\n",
        "\n",
        "ind = []\n",
        "\n",
        "# for each sentence in the corpus\n",
        "for i in range(len(lang_fra)):\n",
        "    \n",
        "    for j in lang_fra[i].split():\n",
        "        if j == '<start>':\n",
        "            empty = True\n",
        "        elif j == '<end>' and empty:\n",
        "            ind.append(i)\n",
        "            print('empty French sentence detected! index:',i)\n",
        "        else: \n",
        "            empty = False\n",
        "    \n",
        "print('# of empty French sentences:', len(ind))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxV3uGPXEfzX",
        "outputId": "485126d4-5583-4e51-fdb0-e585f975acd9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of empty English sentences: 0\n",
            "# of empty French sentences: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split training and test datasets"
      ],
      "metadata": {
        "id": "RretCSdnZ03Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "lang_eng_tr, lang_eng_val, lang_fra_tr, lang_fra_val \\\n",
        "= train_test_split(np.array(lang_eng),np.array(lang_fra),test_size=0.1,shuffle=True,\n",
        "                   random_state=940)\n",
        "\n",
        "# Show length\n",
        "print('training size: %d, test size: %d\\n' % (len(lang_eng_tr), len(lang_eng_val)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTCeNggkL5t0",
        "outputId": "3dbbee7b-2366-4fdb-82fd-b1c98854cce4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size: 149788, test size: 16644\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del lang_eng; del lang_fra"
      ],
      "metadata": {
        "id": "5oc421WMADtP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer training \n",
        "\n",
        "The tokenizers of English and French are trained on the training dataset. But here we'll trian the tokenizers twice. After training them the first time, we determine the number of rare words in each vocabulary and remove the rare words for the second training. Finally, the tokenizers from the second training will be kept."
      ],
      "metadata": {
        "id": "8yoGYQ7S2Gwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train simple tokenizers (1st time)\n",
        "# here we don't need the transformed sequences of integers, we just need to check \n",
        "# vocab sizes inside the tokenizer objects\n",
        "\n",
        "def tokenize(lang,vocab_size=None):\n",
        "    if vocab_size is not None:\n",
        "        print('restricted vocab size training')\n",
        "        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        filters='',num_words=vocab_size)\n",
        "    else:\n",
        "        lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        filters='')\n",
        "\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "    # shape of tensor: Number of examples x Max length of sentence\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                          padding='post')\n",
        "    print('tokenizer trained!')\n",
        "    return tensor, lang_tokenizer\n",
        "\n",
        "# input language is english\n",
        "_, inp_tokenizer = tokenize(lang_eng_tr)\n",
        "\n",
        "# target language is french\n",
        "_, targ_tokenizer = tokenize(lang_fra_tr)"
      ],
      "metadata": {
        "id": "0yr0ikX-KmJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baad3816-dbcc-4ff1-f524-2f5636db0e84"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer trained!\n",
            "tokenizer trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if a word occurs fewer than 5 times in the english corpus, exclude it\n",
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in inp_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)\n",
        "\n",
        "eng_vocab_size = tot_cnt - cnt + 1\n",
        "print(\"final vocab size of English: \", eng_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhnQJPXIArSk",
        "outputId": "db0bdfc8-20c6-4acb-f1a4-99760edc2fbf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary:  61.63721329967235\n",
            "final vocab size of English:  7143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if a word occurs fewer than 5 times in the french corpus, exclude it\n",
        "thresh = 5\n",
        "\n",
        "cnt = 0\n",
        "tot_cnt = 0\n",
        "\n",
        "for key, value in targ_tokenizer.word_counts.items():\n",
        "    tot_cnt = tot_cnt + 1\n",
        "    if value < thresh:\n",
        "        cnt = cnt + 1\n",
        "    \n",
        "print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)\n",
        "\n",
        "fra_vocab_size = tot_cnt - cnt + 1\n",
        "print(\"final vocab size of French: \", fra_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbIhpeEcA4wl",
        "outputId": "68a8d29b-6296-4fe7-d114-e3b2e6fb7e5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "% of rare words in vocabulary:  68.36314546068174\n",
            "final vocab size of French:  9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train simple tokenizers (2nd time)\n",
        "# here we retrain tokenizers with restrictions on vocab sizes\n",
        "# and get the tokenized tensors\n",
        "\n",
        "input_tensor, inp_tokenizer = tokenize(lang_eng_tr,vocab_size=eng_vocab_size)\n",
        "\n",
        "target_tensor, targ_tokenizer = tokenize(lang_fra_tr,vocab_size=fra_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXozN4LVCHSC",
        "outputId": "1b51676c-98e1-42a1-9bd6-a5a6ba869089"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "restricted vocab size training\n",
            "tokenizer trained!\n",
            "restricted vocab size training\n",
            "tokenizer trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demo of word & index mapping of the tokenizers\n",
        "def convert(tokenizer, tensor):\n",
        "    for t in tensor:\n",
        "        if t != 0:\n",
        "            print (\"%d ----> %s\" % (t, tokenizer.index_word[t]))\n",
        "\n",
        "print(\"Input Language; index to word mapping\")\n",
        "convert(inp_tokenizer, input_tensor[0])\n",
        "print()\n",
        "print(\"Target Language; index to word mapping\")\n",
        "convert(targ_tokenizer, target_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zadUw7X-91F",
        "outputId": "720fc9ed-ff38-4142-d890-c6ad9012a91e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> you\n",
            "23 ----> are\n",
            "84 ----> good\n",
            "735 ----> person.\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "142 ----> t\n",
            "59 ----> es\n",
            "15 ----> un\n",
            "3228 ----> chic\n",
            "2015 ----> type.\n",
            "2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to check again the length of each tokenized sequence in both languages. Note that this could be different from the max length of setences that we just regulated."
      ],
      "metadata": {
        "id": "cqaMHYnIg8ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# find out the number of tokens in a sequence\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "metadata": {
        "id": "puLvmOzRBTd2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_targ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wMP2D2wCdNH",
        "outputId": "a2e30237-c988-4d4b-9cc1-726f66fd1f84"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVoUWpu-CroT",
        "outputId": "22bdc475-9f63-49b8-acbf-bcb4f67f405d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab sizes for two langauges\n",
        "vocab_inp_size = inp_tokenizer.num_words\n",
        "vocab_tar_size = targ_tokenizer.num_words"
      ],
      "metadata": {
        "id": "KhbAQfY5XFZ3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder-decoder model using LSTM\n",
        "\n",
        "For building the model, we will see how to use the functional API of Keras instead of the sequential API that we used in CNN Keras tutorial. The functional API gives more flexibility, allowing us to build more complex models such as seq2seq models and models with skip connections.\n",
        "\n",
        "Here we are going to use **teacher forcing** for training, which means the correct token of the target language is passed into the decoder, and then the decoder predicts the next token. If without teacher forcing, the previously decoder-predicted token is passed into the decoder as the current step input."
      ],
      "metadata": {
        "id": "E4jYqrL_aHc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "fq7Cnp4Lqspg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed\n",
        "HIDDEN_DIM = 256\n",
        "EMBED_DIM = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_length_inp, ))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(vocab_inp_size, EMBED_DIM,\n",
        "                    trainable=True)(encoder_inputs)\n",
        "\n",
        "# Encoder LSTM 1\n",
        "encoder_lstm1 = LSTM(HIDDEN_DIM, return_sequences=True,\n",
        "                     return_state=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
        "\n",
        "# Encoder LSTM 2\n",
        "encoder_lstm2 = LSTM(HIDDEN_DIM, return_sequences=True,\n",
        "                     return_state=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# Encoder LSTM 3\n",
        "encoder_lstm3 = LSTM(HIDDEN_DIM, return_state=True,\n",
        "                     return_sequences=True, dropout=0.4,\n",
        "                     recurrent_dropout=0.4)\n",
        "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using encoder_states as the initial state\n",
        "\n",
        "# input layer for target sequences\n",
        "decoder_inputs = Input(shape=(None, ))\n",
        "\n",
        "# Embedding layer\n",
        "dec_emb_layer = Embedding(vocab_tar_size, EMBED_DIM, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM\n",
        "decoder_lstm = LSTM(HIDDEN_DIM, return_sequences=True,\n",
        "                    return_state=True, dropout=0.4,\n",
        "                    recurrent_dropout=0.2)\n",
        "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
        "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(vocab_tar_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "hH_IRVY1dr56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ea6c22-0863-4fd3-e243-a0ad790534ae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 19)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_9 (Embedding)        (None, 19, 256)      1828608     ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_18 (LSTM)                 [(None, 19, 256),    525312      ['embedding_9[0][0]']            \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_19 (LSTM)                 [(None, 19, 256),    525312      ['lstm_18[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)       (None, None, 256)    2400000     ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_20 (LSTM)                 [(None, 19, 256),    525312      ['lstm_19[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_21 (LSTM)                 [(None, None, 256),  525312      ['embedding_10[0][0]',           \n",
            "                                 (None, 256),                     'lstm_20[0][1]',                \n",
            "                                 (None, 256)]                     'lstm_20[0][2]']                \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, None, 9375)  2409375     ['lstm_21[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,739,231\n",
            "Trainable params: 8,739,231\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-4,clipvalue=1.0), \n",
        "              # adam optimizer with gradient clipping\n",
        "\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),  \n",
        "              # sparse categorical crossentropy is the same as cat crossentropy\n",
        "              # but it expects labels to be integers, not one-hot vectors\n",
        "              # accelerates training compared to the original cat crossentropy \n",
        "\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# early stopping by monitoring validation loss\n",
        "# if validation loss didn't decrease in the past two epochs, stop training\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
      ],
      "metadata": {
        "id": "hHbWl7CYpmMY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "UBUmV0jHqvRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the labels for loss calculation are also the target tensor, but offset forward by 1 \n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128 \n",
        "\n",
        "model.fit(x=[input_tensor, target_tensor[:,:-1]], \n",
        "          y=target_tensor.reshape(target_tensor.shape[0],target_tensor.shape[1],1)[:,1:],\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          callbacks=[es],\n",
        "          validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETVLhpdl3ceI",
        "outputId": "06eb9129-27e1-486a-d727-91f874d717c2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1054/1054 [==============================] - 502s 469ms/step - loss: 2.3995 - accuracy: 0.6552 - val_loss: 2.0161 - val_accuracy: 0.6869\n",
            "Epoch 2/50\n",
            "1054/1054 [==============================] - 424s 402ms/step - loss: 1.8373 - accuracy: 0.7070 - val_loss: 1.6905 - val_accuracy: 0.7226\n",
            "Epoch 3/50\n",
            "1054/1054 [==============================] - 361s 342ms/step - loss: 1.5842 - accuracy: 0.7320 - val_loss: 1.5023 - val_accuracy: 0.7398\n",
            "Epoch 4/50\n",
            "1054/1054 [==============================] - 359s 340ms/step - loss: 1.4278 - accuracy: 0.7465 - val_loss: 1.3786 - val_accuracy: 0.7527\n",
            "Epoch 5/50\n",
            "1054/1054 [==============================] - 356s 338ms/step - loss: 1.3140 - accuracy: 0.7585 - val_loss: 1.2847 - val_accuracy: 0.7639\n",
            "Epoch 6/50\n",
            "1054/1054 [==============================] - 355s 337ms/step - loss: 1.2239 - accuracy: 0.7684 - val_loss: 1.2117 - val_accuracy: 0.7724\n",
            "Epoch 7/50\n",
            "1054/1054 [==============================] - 360s 341ms/step - loss: 1.1468 - accuracy: 0.7772 - val_loss: 1.1455 - val_accuracy: 0.7808\n",
            "Epoch 8/50\n",
            "1054/1054 [==============================] - 358s 339ms/step - loss: 1.0791 - accuracy: 0.7854 - val_loss: 1.0902 - val_accuracy: 0.7879\n",
            "Epoch 9/50\n",
            "1054/1054 [==============================] - 361s 342ms/step - loss: 1.0184 - accuracy: 0.7930 - val_loss: 1.0395 - val_accuracy: 0.7950\n",
            "Epoch 10/50\n",
            "1054/1054 [==============================] - 359s 340ms/step - loss: 0.9635 - accuracy: 0.8001 - val_loss: 0.9956 - val_accuracy: 0.8014\n",
            "Epoch 11/50\n",
            "1054/1054 [==============================] - 355s 336ms/step - loss: 0.9143 - accuracy: 0.8072 - val_loss: 0.9566 - val_accuracy: 0.8076\n",
            "Epoch 12/50\n",
            "1054/1054 [==============================] - 351s 333ms/step - loss: 0.8695 - accuracy: 0.8135 - val_loss: 0.9212 - val_accuracy: 0.8130\n",
            "Epoch 13/50\n",
            "1054/1054 [==============================] - 376s 357ms/step - loss: 0.8287 - accuracy: 0.8197 - val_loss: 0.8907 - val_accuracy: 0.8175\n",
            "Epoch 14/50\n",
            "1054/1054 [==============================] - 371s 352ms/step - loss: 0.7915 - accuracy: 0.8255 - val_loss: 0.8624 - val_accuracy: 0.8224\n",
            "Epoch 15/50\n",
            "1054/1054 [==============================] - 351s 333ms/step - loss: 0.7577 - accuracy: 0.8306 - val_loss: 0.8382 - val_accuracy: 0.8263\n",
            "Epoch 16/50\n",
            "1054/1054 [==============================] - 350s 332ms/step - loss: 0.7266 - accuracy: 0.8357 - val_loss: 0.8153 - val_accuracy: 0.8303\n",
            "Epoch 17/50\n",
            "1054/1054 [==============================] - 351s 333ms/step - loss: 0.6976 - accuracy: 0.8406 - val_loss: 0.7963 - val_accuracy: 0.8336\n",
            "Epoch 18/50\n",
            "1054/1054 [==============================] - 346s 329ms/step - loss: 0.6718 - accuracy: 0.8450 - val_loss: 0.7782 - val_accuracy: 0.8364\n",
            "Epoch 19/50\n",
            "1054/1054 [==============================] - 348s 331ms/step - loss: 0.6473 - accuracy: 0.8491 - val_loss: 0.7642 - val_accuracy: 0.8391\n",
            "Epoch 20/50\n",
            "1054/1054 [==============================] - 347s 330ms/step - loss: 0.6255 - accuracy: 0.8532 - val_loss: 0.7488 - val_accuracy: 0.8413\n",
            "Epoch 21/50\n",
            "1054/1054 [==============================] - 350s 332ms/step - loss: 0.6050 - accuracy: 0.8570 - val_loss: 0.7368 - val_accuracy: 0.8439\n",
            "Epoch 22/50\n",
            "1054/1054 [==============================] - 347s 329ms/step - loss: 0.5863 - accuracy: 0.8603 - val_loss: 0.7262 - val_accuracy: 0.8465\n",
            "Epoch 23/50\n",
            "1054/1054 [==============================] - 349s 331ms/step - loss: 0.5688 - accuracy: 0.8635 - val_loss: 0.7159 - val_accuracy: 0.8479\n",
            "Epoch 24/50\n",
            "1054/1054 [==============================] - 350s 332ms/step - loss: 0.5524 - accuracy: 0.8665 - val_loss: 0.7080 - val_accuracy: 0.8498\n",
            "Epoch 25/50\n",
            "1054/1054 [==============================] - 347s 329ms/step - loss: 0.5375 - accuracy: 0.8692 - val_loss: 0.6968 - val_accuracy: 0.8515\n",
            "Epoch 26/50\n",
            "1054/1054 [==============================] - 348s 330ms/step - loss: 0.5238 - accuracy: 0.8717 - val_loss: 0.6904 - val_accuracy: 0.8535\n",
            "Epoch 27/50\n",
            "1054/1054 [==============================] - 351s 333ms/step - loss: 0.5102 - accuracy: 0.8741 - val_loss: 0.6855 - val_accuracy: 0.8542\n",
            "Epoch 28/50\n",
            "1054/1054 [==============================] - 347s 330ms/step - loss: 0.4982 - accuracy: 0.8765 - val_loss: 0.6783 - val_accuracy: 0.8555\n",
            "Epoch 29/50\n",
            "1054/1054 [==============================] - 347s 329ms/step - loss: 0.4860 - accuracy: 0.8787 - val_loss: 0.6724 - val_accuracy: 0.8568\n",
            "Epoch 30/50\n",
            "1054/1054 [==============================] - 346s 328ms/step - loss: 0.4753 - accuracy: 0.8807 - val_loss: 0.6676 - val_accuracy: 0.8580\n",
            "Epoch 31/50\n",
            "1054/1054 [==============================] - 347s 329ms/step - loss: 0.4649 - accuracy: 0.8828 - val_loss: 0.6634 - val_accuracy: 0.8587\n",
            "Epoch 32/50\n",
            "1054/1054 [==============================] - 349s 332ms/step - loss: 0.4552 - accuracy: 0.8847 - val_loss: 0.6605 - val_accuracy: 0.8593\n",
            "Epoch 33/50\n",
            "1054/1054 [==============================] - 363s 345ms/step - loss: 0.4456 - accuracy: 0.8864 - val_loss: 0.6559 - val_accuracy: 0.8603\n",
            "Epoch 34/50\n",
            "1054/1054 [==============================] - 364s 345ms/step - loss: 0.4372 - accuracy: 0.8879 - val_loss: 0.6536 - val_accuracy: 0.8613\n",
            "Epoch 35/50\n",
            "1054/1054 [==============================] - 377s 358ms/step - loss: 0.4286 - accuracy: 0.8898 - val_loss: 0.6503 - val_accuracy: 0.8623\n",
            "Epoch 36/50\n",
            "1054/1054 [==============================] - 378s 358ms/step - loss: 0.4213 - accuracy: 0.8912 - val_loss: 0.6474 - val_accuracy: 0.8626\n",
            "Epoch 37/50\n",
            "1054/1054 [==============================] - 378s 358ms/step - loss: 0.4139 - accuracy: 0.8925 - val_loss: 0.6471 - val_accuracy: 0.8629\n",
            "Epoch 38/50\n",
            "1054/1054 [==============================] - 376s 357ms/step - loss: 0.4066 - accuracy: 0.8940 - val_loss: 0.6438 - val_accuracy: 0.8638\n",
            "Epoch 39/50\n",
            "1054/1054 [==============================] - 374s 355ms/step - loss: 0.3998 - accuracy: 0.8952 - val_loss: 0.6420 - val_accuracy: 0.8645\n",
            "Epoch 40/50\n",
            "1054/1054 [==============================] - 377s 357ms/step - loss: 0.3933 - accuracy: 0.8966 - val_loss: 0.6399 - val_accuracy: 0.8645\n",
            "Epoch 41/50\n",
            "1054/1054 [==============================] - 377s 357ms/step - loss: 0.3872 - accuracy: 0.8977 - val_loss: 0.6386 - val_accuracy: 0.8650\n",
            "Epoch 42/50\n",
            "1054/1054 [==============================] - 375s 356ms/step - loss: 0.3810 - accuracy: 0.8991 - val_loss: 0.6380 - val_accuracy: 0.8653\n",
            "Epoch 43/50\n",
            "1054/1054 [==============================] - 375s 356ms/step - loss: 0.3755 - accuracy: 0.9000 - val_loss: 0.6380 - val_accuracy: 0.8659\n",
            "Epoch 44/50\n",
            "1054/1054 [==============================] - 376s 357ms/step - loss: 0.3699 - accuracy: 0.9011 - val_loss: 0.6350 - val_accuracy: 0.8663\n",
            "Epoch 45/50\n",
            "1054/1054 [==============================] - 357s 339ms/step - loss: 0.3654 - accuracy: 0.9019 - val_loss: 0.6352 - val_accuracy: 0.8665\n",
            "Epoch 46/50\n",
            "1054/1054 [==============================] - 351s 333ms/step - loss: 0.3594 - accuracy: 0.9032 - val_loss: 0.6338 - val_accuracy: 0.8670\n",
            "Epoch 47/50\n",
            "1054/1054 [==============================] - 349s 331ms/step - loss: 0.3548 - accuracy: 0.9039 - val_loss: 0.6332 - val_accuracy: 0.8677\n",
            "Epoch 48/50\n",
            "1054/1054 [==============================] - 349s 331ms/step - loss: 0.3501 - accuracy: 0.9051 - val_loss: 0.6330 - val_accuracy: 0.8678\n",
            "Epoch 49/50\n",
            "1054/1054 [==============================] - 348s 330ms/step - loss: 0.3456 - accuracy: 0.9058 - val_loss: 0.6335 - val_accuracy: 0.8677\n",
            "Epoch 50/50\n",
            "1054/1054 [==============================] - 346s 328ms/step - loss: 0.3415 - accuracy: 0.9069 - val_loss: 0.6333 - val_accuracy: 0.8678\n",
            "Epoch 00050: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e463ed910>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stopping was triggered right at the final epoch. "
      ],
      "metadata": {
        "id": "SLDIxg3ihPnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save checkpoint"
      ],
      "metadata": {
        "id": "YzgeFgq-4V6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./lstm_seq2seq.h5')"
      ],
      "metadata": {
        "id": "Yy40x1gI4W8f"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions\n"
      ],
      "metadata": {
        "id": "-gvx_Rne6oy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction setup\n",
        "\n"
      ],
      "metadata": {
        "id": "1ML6lYyn6sN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here a lot more code is typed compared to the prediction step of a CNN model, or an RNN model for sentiment analysis, because now we are in a sequence-to-sequence task, and the encoder-decoder behaves differently in training and in prediction mode. \n",
        "\n",
        "To be specific, since we used teacher forcing when we trained this encoder-decoder, and we don't have the target sequences available (supposedly) when predicting on the test data, we need to modify the model to make sure it behaves correctly."
      ],
      "metadata": {
        "id": "Db1-vLeRiPAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create another instance of encoder model \n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs,state_h,state_c])\n",
        "\n",
        "# create another instance of decoder model, with hidden states as inputs too\n",
        "\n",
        "# make additional input layers so that the decoder takes in encoder states\n",
        "decoder_state_input_h = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_state_input_c = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_hidden_state_input = Input(shape=(max_length_inp, HIDDEN_DIM))\n",
        "\n",
        "# same embedding layer for the decoder \n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
        "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# decoder model\n",
        "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
        "                      decoder_state_input_h, decoder_state_input_c],\n",
        "                      [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "metadata": {
        "id": "AgQhj_ny7SZY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we code a function that calls the model to translate one English sentence to French (for simplicity). You can also batch up the prediction process, but you might need to change the axis of `np.argmax` in the token sampling step."
      ],
      "metadata": {
        "id": "CP1GZXSUjFEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    '''translates one sequence in input language to sequence in output language'''\n",
        "    \n",
        "    # Encode the input as state vectors.\n",
        "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = targ_tokenizer.word_index['<start>']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    word_count = 0\n",
        "    while not stop_condition:\n",
        "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
        "                + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = targ_tokenizer.index_word[sampled_token_index]\n",
        "\n",
        "        word_count += 1\n",
        "\n",
        "        if sampled_token != '<end>':\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find the stop word.\n",
        "        if sampled_token == '<end>' or word_count \\\n",
        "            > max_length_targ :\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        (e_h, e_c) = (h, c)\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "# To convert sequence to english\n",
        "def seq2eng(seq):\n",
        "    newString = ''\n",
        "    for i in seq:\n",
        "        if i != 0 and i != inp_tokenizer.word_index['<start>'] and i \\\n",
        "            != inp_tokenizer.word_index['<end>']:\n",
        "            newString = newString + inp_tokenizer.index_word[i] + ' '\n",
        "\n",
        "    return newString\n",
        "\n",
        "# To convert sequence to french\n",
        "def seq2fra(seq):\n",
        "    newString = ''\n",
        "    for i in seq:\n",
        "        if i != 0 and i != targ_tokenizer.word_index['<start>'] and i \\\n",
        "            != targ_tokenizer.word_index['<end>']:\n",
        "            newString = newString + targ_tokenizer.index_word[i] + ' '\n",
        "\n",
        "    return newString"
      ],
      "metadata": {
        "id": "4vvk9sOb8vg-"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions on the training set"
      ],
      "metadata": {
        "id": "WBymO6nkZjlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print('English:', seq2eng(input_tensor[i]))\n",
        "    print('Original French:', seq2fra(target_tensor[i]))\n",
        "    print('Predicted French:', decode_sequence(input_tensor[i].reshape(1,  # add one more axis upfront, because our model only takes in tensor with 3 axes, the first one storing different datapoints \n",
        "           max_length_inp)))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LOtzNicl5fw",
        "outputId": "cf853061-d85f-430c-85e6-397bc86d2bff"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: you are good person. \n",
            "Original French: t es un chic type. \n",
            "Predicted French:  vous etes une bonne personne.\n",
            "\n",
            "\n",
            "English: he was real \n",
            "Original French: c etait un vrai \n",
            "Predicted French:  il etait vraiment timide.\n",
            "\n",
            "\n",
            "English: they slept in the same bed. \n",
            "Original French: elles ont dormi dans le meme lit. \n",
            "Predicted French:  elles ont dormi dans le meme lit.\n",
            "\n",
            "\n",
            "English: i ll forgive you. \n",
            "Original French: je vous pardonnerai. \n",
            "Predicted French:  je vous pardonnerai.\n",
            "\n",
            "\n",
            "English: life make vivid on the sensitive plate of his mind. \n",
            "Original French: les experiences de la vie des traces sur la sensible de son esprit. \n",
            "Predicted French:  la sante sur la societe dans une mauvaise direction.\n",
            "\n",
            "\n",
            "English: you must be very hungry now. \n",
            "Original French: tu dois maintenant avoir tres faim. \n",
            "Predicted French:  tu dois etre tres faim maintenant.\n",
            "\n",
            "\n",
            "English: i left my umbrella in the cab. \n",
            "Original French: j ai laisse mon parapluie dans le taxi. \n",
            "Predicted French:  j ai laisse mon parapluie dans le taxi.\n",
            "\n",
            "\n",
            "English: tom is not here. \n",
            "Original French: tom est pas ici. \n",
            "Predicted French:  tom est pas ici.\n",
            "\n",
            "\n",
            "English: my father left me lot of money in his will. \n",
            "Original French: mon pere a laisse beaucoup argent dans son \n",
            "Predicted French:  mon pere a pose beaucoup argent dans son\n",
            "\n",
            "\n",
            "English: is he just one trick \n",
            "Original French: n t il qu un unique talent \n",
            "Predicted French:  est ce qu un unique simple\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions on the test set"
      ],
      "metadata": {
        "id": "HVm4NfoAZ3gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_tokenize(lang,tokenizer):\n",
        "    tensor = tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "    # shape of tensor: Number of examples x Max length of sentence\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                          padding='post')\n",
        "    print('test data tokenized!')\n",
        "    return tensor\n",
        "\n",
        "# tokenize test data\n",
        "input_tensor = test_tokenize(lang_eng_val,inp_tokenizer)\n",
        "target_tensor = test_tokenize(lang_fra_val,targ_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gerRbR3qa3q6",
        "outputId": "46d2ad6a-cd61-43bd-fe8c-71b3b29b44b1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test data tokenized!\n",
            "test data tokenized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 10):\n",
        "    print('English:', seq2eng(input_tensor[i]))\n",
        "    print('Original French:', seq2fra(target_tensor[i]))\n",
        "    print('Predicted French:', decode_sequence(input_tensor[i].reshape(1,  # add one more axis upfront, because our model only takes in tensor with 3 axes, the first one storing different datapoints \n",
        "           max_length_inp)))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VDNiGpclbbz",
        "outputId": "748c11a6-b785-44c5-8443-3776c3545ba9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: she turned the slowly. \n",
            "Original French: elle tourna lentement la poignee de porte. \n",
            "Predicted French:  elle eteignit lentement.\n",
            "\n",
            "\n",
            "English: i sorry didn recognize you. \n",
            "Original French: je suis desolee je ne ai pas reconnue. \n",
            "Predicted French:  je suis desole je ne vous ai pas reconnue.\n",
            "\n",
            "\n",
            "English: tom is wearing \n",
            "Original French: tom porte des \n",
            "Predicted French:  tom porte des lunettes de\n",
            "\n",
            "\n",
            "English: i hope this won happen again. \n",
            "Original French: j espere que ceci arrivera plus. \n",
            "Predicted French:  j espere que ca ne va pas arriver.\n",
            "\n",
            "\n",
            "English: you need to save the princess. \n",
            "Original French: il vous faut sauver la princesse. \n",
            "Predicted French:  il faut que tu la princesse.\n",
            "\n",
            "\n",
            "English: she ran outside half naked. \n",
            "Original French: elle couru dehors moitie nue. \n",
            "Predicted French:  elle courut dehors moitie nue.\n",
            "\n",
            "\n",
            "English: everything is broken. \n",
            "Original French: tout est brise. \n",
            "Predicted French:  tout est casse.\n",
            "\n",
            "\n",
            "English: long story short was fired. \n",
            "Original French: en ai ete vire. \n",
            "Predicted French:  une longue douleur ete\n",
            "\n",
            "\n",
            "English: i feel like ve known you forever. \n",
            "Original French: j ai impression de avoir toujours connu. \n",
            "Predicted French:  j ai impression de vous avoir perdu connaissance.\n",
            "\n",
            "\n",
            "English: she smiled \n",
            "Original French: elle sourit avec bonheur. \n",
            "Predicted French:  elle sourit sans enthousiasme.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "https://blog.paperspace.com/introduction-to-seq2seq-models/; \n",
        "\n",
        "https://blog.paperspace.com/implement-seq2seq-for-text-summarization-keras/"
      ],
      "metadata": {
        "id": "LMT1zDbRmH0v"
      }
    }
  ]
}