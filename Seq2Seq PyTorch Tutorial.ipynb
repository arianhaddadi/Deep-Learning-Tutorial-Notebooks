{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Different categories of RNN models:\n",
        "\n",
        " - Many-to-one (sentiment analysis, fake news detection)\n",
        " - many-to-many (i.e. seq2seq, machine translation, text summary)\n",
        " - one-to-many (image captioning), one-to-one (plain MLP networks)\n",
        " \n",
        "\n",
        "We previously looked at a many-to-one model for a sentiment analysis task (the IMDB dataset), and now let's dive into a more complicated type of RNN: many-to-many, i.e. seq2seq."
      ],
      "metadata": {
        "id": "1M0jlU56kXaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages and download data\n",
        "\n",
        "Dataset introduction: \n",
        "\n",
        "This [dataset](https://www.manythings.org/anki/) consists of many combinations of bilingual sentence pairs. The lengths of the sentences and the vocabulary sizes are relatively small. In this notebook, we choose the subset of English-French sentence pairs. \n",
        "\n",
        "Main steps of notebook include:\n",
        " - Preprocess raw text data (regex data cleaning, deciding max lengths, tokenizer training)\n",
        " - Model setup for training (using keras functional API instead of sequential API)\n",
        " - Model setup for predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "1tGMb5p-Y0u5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fsg4Y-jyEMm_"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import math\n",
        "import re\n",
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchtext\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import os \n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "# set seed\n",
        "seed_everything(940)\n",
        "\n",
        "# setup GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # check is GPU is available"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IWSLT2016\n",
        "\n",
        "# a dataset for machine translation (English to French)\n",
        "raw_text = IWSLT2016(root='./', split=('train', 'valid', 'test'), language_pair=('en','fr'), valid_set='tst2013', test_set='tst2014')\n",
        "train = raw_text[0]\n",
        "valid = raw_text[1]\n",
        "test = raw_text[2]"
      ],
      "metadata": {
        "id": "hEcngV7Ko-U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849619ee-3500-4bdd-8630-a127c3ea4966"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 188M/188M [00:01<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# of training examples:', len(train))\n",
        "print('# of validation examples:',len(valid))\n",
        "print(\"# of test examples:\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpU_Ty6lp7oN",
        "outputId": "a32a52ff-ab11-450e-cb17-06df72015894"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of training examples: 220400\n",
            "# of validation examples: 1026\n",
            "# of test examples: 1305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess raw text data\n",
        "\n",
        "In this section, we will perform standard text preprocessing such as lowercasing characters, removing miscellaneous symbols, standardize whitespace symbols. A majority of the work is done using the regular expression library of python. Then we will train a tokenizer from scratch.  "
      ],
      "metadata": {
        "id": "ptSeNDIyY7bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RegEx preprocessing"
      ],
      "metadata": {
        "id": "MijRuU57ZsIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lists for storing data\n",
        "text_tr = []\n",
        "text_val = []\n",
        "text_test = []\n",
        "\n",
        "for eng, fra in train:\n",
        "    text_tr.append((eng,fra))\n",
        "\n",
        "for eng, fra in valid:\n",
        "    text_val.append((eng,fra))\n",
        "\n",
        "for eng, fra in test:\n",
        "    text_test.append((eng,fra))"
      ],
      "metadata": {
        "id": "4ge7CAGxEWlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(s,verbose=False):\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # convert characters to lowercase\n",
        "    # convert characters to ascii for regex preprocessing\n",
        "    s = unicode_to_ascii(s.lower())\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # Remove the characters - <>()|&©ø\"',;?~*!\n",
        "    s = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove punctuations at the end of a word\n",
        "    s = re.sub(\"(\\.\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\-\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\:\\s+)\", r\" \", s)\n",
        "    s = re.sub(\"(\\!\\s+)\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove other characters that are not letters \n",
        "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # remove multiple whitespaces\n",
        "    s = re.sub(r'(\\s+)', r' ', s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # Remove the single character hanging between any two spaces\n",
        "    s = re.sub(\"(\\s+.\\s+)\", r\" \", s)\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # removes whitespaces in the beginning and the end\n",
        "    s = s.strip()\n",
        "    if verbose:\n",
        "        print(s)\n",
        "\n",
        "    # add start and end of sentence tokens\n",
        "    s = '[SOS]' +' '+ s +' '+'[EOS]'\n",
        "    return s\n",
        "\n",
        "s = '  1234 reguLAR eXpreSSion sooo\\t hard!!! - <>()|&©ø\"\\',;?~*   '\n",
        "preprocess_sentence(s,verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Eanr_id8KiAh",
        "outputId": "3f1a0a55-88ad-473a-ae74-d0d07d7a9597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1234 reguLAR eXpreSSion sooo\t hard!!! - <>()|&©ø\"',;?~*   \n",
            "  1234 regular expression sooo\t hard!!! - <>()|&©ø\"',;?~*   \n",
            "  1234 regular expression sooo\t hard    -                   \n",
            "  1234 regular expression sooo\t hard     \n",
            " regular expression sooo hard \n",
            " regular expression sooo hard \n",
            " regular expression sooo hard \n",
            "regular expression sooo hard\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[SOS] regular expression sooo hard [EOS]'"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean raw text using regex"
      ],
      "metadata": {
        "id": "YSfn7Qaj38k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_corpus(lang):\n",
        "    # list to store preprocessed text\n",
        "    lang_eng = []\n",
        "    lang_fra = []\n",
        "\n",
        "    # preprocess raw text\n",
        "    for eng, fra in lang:\n",
        "        preprocessed_eng = preprocess_sentence(eng)\n",
        "        preprocessed_fra = preprocess_sentence(fra)\n",
        "        lang_eng.append(preprocessed_eng)\n",
        "        lang_fra.append(preprocessed_fra)\n",
        "    \n",
        "    return lang_eng, lang_fra\n"
      ],
      "metadata": {
        "id": "DnIkqmzi18GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_eng_tr, lang_fra_tr = process_corpus(text_tr)\n",
        "lang_eng_val, lang_fra_val = process_corpus(text_val)\n",
        "lang_eng_test, lang_fra_test = process_corpus(text_test)"
      ],
      "metadata": {
        "id": "keevHyrdtFZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lang_eng_tr[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P9GVyRH_YkF",
        "outputId": "0c898ab0-7171-4bca-b753-09f27a9dfe1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[SOS] david gallo this is bill lange m dave gallo [EOS]',\n",
              " '[SOS] and we re going to tell you some stories from the sea here in video [EOS]',\n",
              " '[SOS] we ve got some of the most incredible video of titanic that ever been seen and we re not going to show you any of it [EOS]',\n",
              " '[SOS] the truth of the matter is that the titanic even though it breaking all sorts of box office records it not the most exciting story from the sea [EOS]',\n",
              " '[SOS] and the problem think is that we take the ocean for granted [EOS]']"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_fra_tr[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hgZtOhZ_jfu",
        "outputId": "0e17df4e-e9cb-48fb-b4f1-41e3075fedbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[SOS] david gallo voici bill lange je suis dave gallo [EOS]',\n",
              " '[SOS] nous allons vous raconter quelques histoires de la mer en video [EOS]',\n",
              " '[SOS] nous avons des videos du titanic parmi les plus spectaculaires jamais vues et nous allons pas vous en montrer une image [EOS]',\n",
              " '[SOS] la verite est que le titanic meme il continue de battre toutes les records de recettes est pas histoire la plus passionnante [EOS]',\n",
              " '[SOS] le probleme je crois est qu on tient ocean pour acquis [EOS]']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del text_tr; del text_val; del text_test;"
      ],
      "metadata": {
        "id": "-RxPNo-jiCSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select sentences that are shorter than the maximum lengths allowed\n",
        "\n",
        "In a large dataset, it is possible that a very few sentences are very lengthy, while the remaining majority are much shorter. In this case, if we keep those lengthy sentences, then we need to zero pad the remaining ones up to the same length, which requires the machine to store a lot of zeros for nothing. To avoid this, we simply look at the distribution of lengths for both languages, and regulate the max lengths. "
      ],
      "metadata": {
        "id": "4Gs9sQoC42Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count lengths of sentences in english and french\n",
        "eng_lengths = np.array([len(sentence.split()) for sentence in lang_eng_tr])\n",
        "fra_lengths = np.array([len(sentence.split()) for sentence in lang_fra_tr])"
      ],
      "metadata": {
        "id": "2EELv4qD2SW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(eng_lengths,bins=np.arange(0,130,5),density=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Af25QPHR3AHH",
        "outputId": "a802c93f-d828-4905-8ecc-b9766b92ec5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(fra_lengths,bins=np.arange(0,130,5),density=True);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5jxkxZnJ3E3N",
        "outputId": "35ed82e0-2226-4185-ffa3-b20712be2dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ2UlEQVR4nO3df5BdZ13H8ffHxIZfQwtpZCQpbJgEmYAKuBYcgXGoaEqR4NgOqcxQx8xURjqgyGA6jJ3S4Y9WHSoOFe3QSskgLUbQHRqsQBkdHYjZQIWmJbJtI00tsv1BtGBpQ7/+cU/wznLTPZtssnefvl8zO3vO8zx393vu2f3cs+ec+2yqCklSu35kqQuQJJ1YBr0kNc6gl6TGGfSS1DiDXpIat3KpC5jr9NNPr4mJiaUuQ5KWlb17995XVWtG9Y1d0E9MTDA9Pb3UZUjSspLkP47W1+vUTZLNSfYnmUmyfUT/qiQ3dP27k0x07RNJ/jfJLd3Hnx/rRkiSjs28R/RJVgBXAa8BDgJ7kkxV1W1Dw7YBD1bVhiRbgSuAN3Z9d1TVixe5bklST32O6M8EZqrqzqp6BLge2DJnzBbgum55J3BWkixemZKkY9Un6NcCdw+tH+zaRo6pqsPAIWB117c+yZeT/GOSV476BkkuTDKdZHp2dnZBGyBJenwn+vbKe4HnVNVLgHcAf5Xk6XMHVdXVVTVZVZNr1oy8aCxJOkZ9gv4e4Iyh9XVd28gxSVYCpwL3V9X3qup+gKraC9wBPP94i5Yk9dcn6PcAG5OsT3IKsBWYmjNmCrigWz4XuLmqKsma7mIuSZ4HbATuXJzSJUl9zHvXTVUdTnIRcBOwAri2qvYluQyYrqop4BpgR5IZ4AEGLwYArwIuS/Io8Bjwlqp64ERsiCRptIzbfPSTk5PlG6YkaWGS7K2qyVF9Y/fO2HE3sf3GBY0/cPk5J6gSSerHSc0kqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxvYI+yeYk+5PMJNk+on9Vkhu6/t1JJub0PyfJQ0neuThlS5L6mjfok6wArgLOBjYB5yfZNGfYNuDBqtoAXAlcMaf/fcCnj79cSdJC9TmiPxOYqao7q+oR4Hpgy5wxW4DruuWdwFlJApDkDcBdwL7FKVmStBB9gn4tcPfQ+sGubeSYqjoMHAJWJ3ka8PvAex7vGyS5MMl0kunZ2dm+tUuSejjRF2MvBa6sqoceb1BVXV1Vk1U1uWbNmhNckiQ9sazsMeYe4Iyh9XVd26gxB5OsBE4F7gdeBpyb5A+B04DHkjxcVR847solSb30Cfo9wMYk6xkE+lbg1+eMmQIuAL4AnAvcXFUFvPLIgCSXAg8Z8pJ0cs0b9FV1OMlFwE3ACuDaqtqX5DJguqqmgGuAHUlmgAcYvBhIksZAnyN6qmoXsGtO2yVDyw8D583zNS49hvokScfJd8ZKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Ljer0zVsduYvuNCxp/4PJzTlAlkp6oPKKXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuOe8JOaLXTSMUlabjyil6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4XkGfZHOS/Ulmkmwf0b8qyQ1d/+4kE137mUlu6T7+LcmvLm75kqT5zBv0SVYAVwFnA5uA85NsmjNsG/BgVW0ArgSu6NpvBSar6sXAZuAvkjzh59eRpJOpzxH9mcBMVd1ZVY8A1wNb5ozZAlzXLe8EzkqSqvpuVR3u2p8E1GIULUnqr0/QrwXuHlo/2LWNHNMF+yFgNUCSlyXZB3wVeMtQ8P9AkguTTCeZnp2dXfhWSJKO6oRfjK2q3VX1QuBngYuTPGnEmKurarKqJtesWXOiS5KkJ5Q+QX8PcMbQ+rqubeSY7hz8qcD9wwOq6nbgIeBFx1qsJGnh+gT9HmBjkvVJTgG2AlNzxkwBF3TL5wI3V1V1j1kJkOS5wAuAA4tSuSSpl3nvgKmqw0kuAm4CVgDXVtW+JJcB01U1BVwD7EgyAzzA4MUA4BXA9iSPAo8Bv11V952IDZEkjdbrVseq2gXsmtN2ydDyw8B5Ix63A9hxnDVKko6D74yVpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIa57/1GzMT229c0PgDl59zgiqR1AqP6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuN6BX2SzUn2J5lJsn1E/6okN3T9u5NMdO2vSbI3yVe7z69e3PIlSfOZN+iTrACuAs4GNgHnJ9k0Z9g24MGq2gBcCVzRtd8H/EpV/SRwAbBjsQqXJPXT54j+TGCmqu6sqkeA64Etc8ZsAa7rlncCZyVJVX25qv6za98HPDnJqsUoXJLUT5+gXwvcPbR+sGsbOaaqDgOHgNVzxvwa8KWq+t7cb5DkwiTTSaZnZ2f71i5J6uGkXIxN8kIGp3N+a1R/VV1dVZNVNblmzZqTUZIkPWH0Cfp7gDOG1td1bSPHJFkJnArc362vAz4JvLmq7jjegiVJC9Mn6PcAG5OsT3IKsBWYmjNmisHFVoBzgZurqpKcBtwIbK+qf1msoiVJ/c0b9N0594uAm4DbgY9X1b4klyV5fTfsGmB1khngHcCRWzAvAjYAlyS5pfv4sUXfCknSUa3sM6iqdgG75rRdMrT8MHDeiMe9F3jvcdYoSToOvjNWkhpn0EtS43qdutH4mth+44Ifc+Dyc05AJZLGlUf0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxq1c6gJ08k1sv3FB4w9cfs4JqkTSyeARvSQ1zqCXpMYZ9JLUOINekhpn0EtS43oFfZLNSfYnmUmyfUT/qiQ3dP27k0x07auTfD7JQ0k+sLilS5L6mDfok6wArgLOBjYB5yfZNGfYNuDBqtoAXAlc0bU/DPwB8M5Fq1iStCB9jujPBGaq6s6qegS4HtgyZ8wW4LpueSdwVpJU1Xeq6p8ZBL4kaQn0Cfq1wN1D6we7tpFjquowcAhY3beIJBcmmU4yPTs72/dhkqQexuJibFVdXVWTVTW5Zs2apS5HkprSJ+jvAc4YWl/XtY0ck2QlcCpw/2IUKEk6Pn2Cfg+wMcn6JKcAW4GpOWOmgAu65XOBm6uqFq9MSdKxmndSs6o6nOQi4CZgBXBtVe1LchkwXVVTwDXAjiQzwAMMXgwASHIAeDpwSpI3AL9UVbct/qZIkkbpNXtlVe0Cds1pu2Ro+WHgvKM8duI46pMkHaexuBgrSTpxDHpJapxBL0mNM+glqXH+K0HNy389KC1vHtFLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxTIGjROWWCNF48opekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXHeR68l53330onVXNAvNDQkqXWeupGkxhn0ktQ4g16SGtfcOXq1z4u30sJ4RC9JjTPoJalxnrpR847llltP96glHtFLUuM8opdG8IKvWtIr6JNsBt4PrAA+VFWXz+lfBXwE+BngfuCNVXWg67sY2AZ8H3hbVd20aNVLY8IXBo2zeYM+yQrgKuA1wEFgT5KpqrptaNg24MGq2pBkK3AF8MYkm4CtwAuBZwOfTfL8qvr+Ym+ItJz4wqCTqc8R/ZnATFXdCZDkemALMBz0W4BLu+WdwAeSpGu/vqq+B9yVZKb7el9YnPKlJ4YW5nDyxWrp9An6tcDdQ+sHgZcdbUxVHU5yCFjdtX9xzmPXzv0GSS4ELuxWH0qyv1f1o50O3Hccj19qy71+cBvGwdjVnysW/JCx24ZjcDK34blH6xiLi7FVdTVw9WJ8rSTTVTW5GF9rKSz3+sFtGAfLvX5wGxZTn9sr7wHOGFpf17WNHJNkJXAqg4uyfR4rSTqB+gT9HmBjkvVJTmFwcXVqzpgp4IJu+Vzg5qqqrn1rklVJ1gMbgX9dnNIlSX3Me+qmO+d+EXATg9srr62qfUkuA6aragq4BtjRXWx9gMGLAd24jzO4cHsYeOtJuONmUU4BLaHlXj+4DeNgudcPbsOiyeDAW5LUKqdAkKTGGfSS1Lhmgj7J5iT7k8wk2b7U9fSR5Iwkn09yW5J9Sd7etT8zyWeSfL37/IylrvXxJFmR5MtJPtWtr0+yu9sXN3QX8cdWktOS7EzytSS3J/m5ZbgPfrf7Gbo1yceSPGnc90OSa5N8K8mtQ20jn/cM/Gm3LV9J8tKlq/wHtY6q/4+6n6OvJPlkktOG+i7u6t+f5JdPZq1NBP3QNA1nA5uA87vpF8bdYeD3qmoT8HLgrV3d24HPVdVG4HPd+jh7O3D70PoVwJVVtQF4kMEUGePs/cDfV9ULgJ9msC3LZh8kWQu8DZisqhcxuGniyFQk47wfPgxsntN2tOf9bAZ37W1k8ObKD56kGh/Ph/nh+j8DvKiqfgr4d+BigDnTwWwG/qzLrZOiiaBnaJqGqnoEODJNw1irqnur6kvd8v8wCJi1DGq/rht2HfCGpalwfknWAecAH+rWA7yawVQYMP71nwq8isGdY1TVI1X1bZbRPuisBJ7cvY/lKcC9jPl+qKp/YnCX3rCjPe9bgI/UwBeB05L8+MmpdLRR9VfVP1TV4W71iwzeOwRD08FU1V3AkelgTopWgn7UNA0/NNXCOEsyAbwE2A08q6ru7bq+CTxricrq40+AdwGPdeurgW8P/bCP+75YD8wCf9mdfvpQkqeyjPZBVd0D/DHwDQYBfwjYy/LaD0cc7Xlfjr/jvwl8ulte0vpbCfplLcnTgL8Bfqeq/nu4r3vj2VjeA5vkdcC3qmrvUtdyHFYCLwU+WFUvAb7DnNM047wPALrz2FsYvGg9G3gqP3xKYdkZ9+f98SR5N4NTsx9d6lqgnaBftlMtJPlRBiH/0ar6RNf8X0f+LO0+f2up6pvHzwOvT3KAwemyVzM4331adwoBxn9fHAQOVtXubn0ng+BfLvsA4BeBu6pqtqoeBT7BYN8sp/1wxNGe92XzO57kN4DXAW+q/3+j0pLW30rQ95mmYex057OvAW6vqvcNdQ1PKXEB8Hcnu7Y+quriqlpXVRMMnvObq+pNwOcZTIUBY1w/QFV9E7g7yU90TWcxeCf3stgHnW8AL0/ylO5n6sg2LJv9MORoz/sU8Obu7puXA4eGTvGMjQz+SdO7gNdX1XeHupZ2OpiqauIDeC2Dq9x3AO9e6np61vwKBn+afgW4pft4LYPz3J8Dvg58FnjmUtfaY1t+AfhUt/y87od4BvhrYNVS1zdP7S8Gprv98LfAM5bbPgDeA3wNuBXYAawa9/0AfIzBNYVHGfxlte1ozzsQBnfW3QF8lcEdRuNY/wyDc/FHfp//fGj8u7v69wNnn8xanQJBkhrXyqkbSdJRGPSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcf8Ha0dqCAlU5qoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After looking at the histograms, we can restrict the length of English sentences to 80, and the length of French sentences to 80."
      ],
      "metadata": {
        "id": "n1KxnB3G3_8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# condition of a pair getting selected\n",
        "def select_sentence_pair(row):\n",
        "    # selected if both sentences are shorter than the max lengths\n",
        "    if len(row.iloc[0].split()) < max_length_inp and len(row.iloc[1].split()) < max_length_targ:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# hard coded max lengths\n",
        "max_length_targ, max_length_inp = 80, 80\n",
        "\n",
        "# delete sentences exceeding max lengths\n",
        "def filter_text(lang_eng, lang_fra):\n",
        "    # put two lists into a df to select pairs\n",
        "    cleaned_text = pd.DataFrame({'eng_cleaned':lang_eng,'fra_cleaned':lang_fra})\n",
        "\n",
        "    keep = cleaned_text.apply(select_sentence_pair,axis=1)\n",
        "    cleaned_text['keep'] = keep\n",
        "\n",
        "    # filter out unwanted data \n",
        "    cleaned_text = cleaned_text[cleaned_text.keep == 1]\n",
        "\n",
        "    lang_eng_new = cleaned_text.iloc[:,0].tolist()\n",
        "    lang_fra_new = cleaned_text.iloc[:,1].tolist()\n",
        "\n",
        "    return lang_eng_new, lang_fra_new\n",
        "  \n",
        "lang_eng_tr, lang_fra_tr = filter_text(lang_eng_tr, lang_fra_tr)\n",
        "lang_eng_val, lang_fra_val = filter_text(lang_eng_val, lang_fra_val)\n",
        "lang_eng_test, lang_fra_test = filter_text(lang_eng_test, lang_fra_test)"
      ],
      "metadata": {
        "id": "ieXNkQSV470x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('# of training examples after filter:', len(lang_eng_tr))\n",
        "print('# of validation examples after filter:',len(lang_eng_val))\n",
        "print('# of test examples after filter:',len(lang_eng_test))\n",
        "#print(\"# of test examples:\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4ErXwhNvRaD",
        "outputId": "af0a5125-639a-4fe4-81fc-7f330bbd6968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of training examples after filter: 219562\n",
            "# of validation examples after filter: 1022\n",
            "# of test examples after filter: 1304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Detect empty sentences\n",
        "\n",
        "If any empty sentence detected in a pair, then we will delete that pair from the data."
      ],
      "metadata": {
        "id": "IrqcbvmyE-2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_empty_sentences(lang_eng, lang_fra):\n",
        "    # detect if there are any empty sentences,i.e, which only have '<start>' and '<end>' tokens\n",
        "    eng_ind = []\n",
        "\n",
        "    # for each sentence in the corpus\n",
        "    for i in range(len(lang_eng)):\n",
        "        \n",
        "        for j in lang_eng[i].split():\n",
        "            if j == '[SOS]':\n",
        "                empty = True\n",
        "            elif j == '[EOS]' and empty:\n",
        "                eng_ind.append(i)\n",
        "                #print('empty English sentence detected! index:',i)\n",
        "            else: \n",
        "                empty = False\n",
        "        \n",
        "    print('# of empty English sentences:', len(eng_ind))\n",
        "\n",
        "    fra_ind = []\n",
        "\n",
        "    # for each sentence in the corpus\n",
        "    for i in range(len(lang_fra)):\n",
        "        \n",
        "        for j in lang_fra[i].split():\n",
        "            if j == '[SOS]':\n",
        "                empty = True\n",
        "            elif j == '{[EOS]}' and empty:\n",
        "                fra_ind.append(i)\n",
        "                #print('empty French sentence detected! index:',i)\n",
        "            else: \n",
        "                empty = False\n",
        "        \n",
        "    print('# of empty French sentences:', len(fra_ind))\n",
        "\n",
        "    final_ind = set(eng_ind + fra_ind)\n",
        "\n",
        "    print('# of datapoints to be deleted:', len(final_ind))\n",
        "\n",
        "    return list(final_ind)"
      ],
      "metadata": {
        "id": "oxV3uGPXEfzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('detecting empty sentences in training data')\n",
        "\n",
        "delete_idx = detect_empty_sentences(lang_eng_tr, lang_fra_tr)\n",
        "\n",
        "# delete unwanted sentences\n",
        "lang_eng_tr = [lang_eng_tr[i] for i in range(len(lang_eng_tr)) if i not in delete_idx]\n",
        "lang_fra_tr = [lang_fra_tr[i] for i in range(len(lang_fra_tr)) if i not in delete_idx]\n",
        "\n",
        "print()\n",
        "print('detecting empty sentences in validation data')\n",
        "\n",
        "delete_idx = detect_empty_sentences(lang_eng_val, lang_fra_val)\n",
        "\n",
        "# delete unwanted sentences\n",
        "lang_eng_val = [lang_eng_val[i] for i in range(len(lang_eng_val)) if i not in delete_idx]\n",
        "lang_fra_val = [lang_fra_val[i] for i in range(len(lang_fra_val)) if i not in delete_idx]\n",
        "\n",
        "print()\n",
        "print('detecting empty sentences in test data')\n",
        "\n",
        "delete_idx = detect_empty_sentences(lang_eng_test, lang_fra_test)\n",
        "\n",
        "# delete unwanted sentences\n",
        "lang_eng_test = [lang_eng_test[i] for i in range(len(lang_eng_test)) if i not in delete_idx]\n",
        "lang_fra_test = [lang_fra_test[i] for i in range(len(lang_fra_test)) if i not in delete_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qg5np1Kvscw",
        "outputId": "c2abb498-994e-4a81-f370-e74d220a24a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detecting empty sentences in training data\n",
            "# of empty English sentences: 20\n",
            "# of empty French sentences: 0\n",
            "# of datapoints to be deleted: 20\n",
            "\n",
            "detecting empty sentences in validation data\n",
            "# of empty English sentences: 0\n",
            "# of empty French sentences: 0\n",
            "# of datapoints to be deleted: 0\n",
            "\n",
            "detecting empty sentences in test data\n",
            "# of empty English sentences: 0\n",
            "# of empty French sentences: 0\n",
            "# of datapoints to be deleted: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer training \n",
        "\n",
        "Here we use a SOTA tokenizer training algorithm, and we are manually regulating the vocabulary sizes."
      ],
      "metadata": {
        "id": "8yoGYQ7S2Gwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tokenizers\n",
        "from tokenizers import Tokenizer"
      ],
      "metadata": {
        "id": "RDDDk2fXxsG9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.models import WordPiece\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import WordPieceTrainer\n",
        "\n",
        "# one tokenizer for each language\n",
        "eng_tokenizer = Tokenizer(WordPiece())\n",
        "fra_tokenizer = Tokenizer(WordPiece())\n",
        "\n",
        "eng_tokenizer.pre_tokenizer = Whitespace()\n",
        "fra_tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "def yield_text(data_iter):\n",
        "    '''Creates a generator for all texts in one language'''\n",
        "\n",
        "    for text in data_iter:\n",
        "        yield text\n",
        "\n",
        "trainer = WordPieceTrainer(vocab_size=10000, special_tokens=['[UNK]','[SOS]','[EOS]'])\n",
        "\n",
        "eng_tokenizer.train_from_iterator(lang_eng_tr, trainer=trainer)\n",
        "fra_tokenizer.train_from_iterator(lang_fra_tr, trainer=trainer)"
      ],
      "metadata": {
        "id": "LLIhgq_qwwak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizers\n",
        "#eng_tokenizer.save(\"./eng_tok.json\")\n",
        "#fra_tokenizer.save(\"./fra_tok.json\")\n",
        "\n",
        "# load tokenizers\n",
        "eng_tokenizer = Tokenizer.from_file(\"./eng_tok.json\")\n",
        "fra_tokenizer = Tokenizer.from_file(\"./fra_tok.json\")"
      ],
      "metadata": {
        "id": "hPI5wrIyux2i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eng_tokenizer.id_to_token(0),eng_tokenizer.id_to_token(1),eng_tokenizer.id_to_token(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wPLt6PspzNCK",
        "outputId": "b3b64428-fceb-48ab-85cb-a96750b5c8db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[UNK] [SOS] [EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fra_tokenizer.id_to_token(0),fra_tokenizer.id_to_token(1),fra_tokenizer.id_to_token(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Xqvjw7oGzPJh",
        "outputId": "1d0b16d3-c10f-4acb-a49d-105d76af2181"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[UNK] [SOS] [EOS]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab sizes for two langauges\n",
        "vocab_eng_size = eng_tokenizer.get_vocab_size()\n",
        "vocab_fra_size = fra_tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "id": "KhbAQfY5XFZ3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now preprocessing is finished, store all data into csv files and release memory\n",
        "\n",
        "train_df = pd.DataFrame({'eng':lang_eng_tr,'fra':lang_fra_tr})\n",
        "valid_df = pd.DataFrame({'eng':lang_eng_val,'fra':lang_fra_val})\n",
        "test_df = pd.DataFrame({'eng':lang_eng_test,'fra':lang_fra_test})\n",
        "\n",
        "train_df.to_csv('train_df.csv',index=False)\n",
        "valid_df.to_csv('valid_df.csv',index=False)\n",
        "test_df.to_csv('test_df.csv',index=False)\n",
        "\n",
        "del train_df; del valid_df; del test_df; del lang_eng_tr; del lang_fra_tr; del lang_eng_val\n",
        "del lang_fra_val; del lang_eng_test; del lang_fra_test;\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "dkvZAf-qiIs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and data loaders"
      ],
      "metadata": {
        "id": "mLB0p3wanlKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets"
      ],
      "metadata": {
        "id": "BbIuIEZFsFsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, csv_path):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # if the indices passed in are in a tensor, convert to list\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # extract rows of the passed indicies and convert to arrays\n",
        "        if isinstance(idx,list):\n",
        "            eng = self.data.iloc[idx,0].values\n",
        "            fra = self.data.iloc[idx,1].values\n",
        "        else: \n",
        "            eng = np.array([self.data.iloc[idx,0]])\n",
        "            fra = np.array([self.data.iloc[idx,1]])\n",
        "        \n",
        "        sample = {'eng':eng,'fra':fra}\n",
        "\n",
        "        return sample\n",
        "\n",
        "train_set = TextDataset('train_df.csv')\n",
        "valid_set = TextDataset('valid_df.csv')"
      ],
      "metadata": {
        "id": "HGkLwLe7o17a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipelines"
      ],
      "metadata": {
        "id": "_CcbbvYUcmEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cut(x, maxlen=80):\n",
        "    return x[0:maxlen] if len(x) > maxlen else x\n",
        "\n",
        "def eng_pipeline(text):\n",
        "    text = eng_tokenizer.encode(text).ids\n",
        "    #text = cut(text, maxlen=max_length_inp)\n",
        "    return text\n",
        "\n",
        "def fra_pipeline(text):\n",
        "    text = fra_tokenizer.encode(text).ids\n",
        "    #text = cut(text, maxlen=max_length_targ)\n",
        "    return text"
      ],
      "metadata": {
        "id": "6j9Kcu6yc6nx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Collate function and data loaders"
      ],
      "metadata": {
        "id": "IhWPqvq_eA1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "    '''\n",
        "    Transforms texts and labels according to corresponding pipelines,\n",
        "    zero pad shorter sequences, and stack all sequences in the batch along a new axis'''\n",
        "\n",
        "    eng_list, fra_list = [], []\n",
        "\n",
        "    for pair in batch:\n",
        "        assert len(pair['eng']) == 1, 'length of one value in dict more than 1!'\n",
        "        \n",
        "        eng = pair['eng'][0]\n",
        "        fra = pair['fra'][0]\n",
        "        \n",
        "        # convert text to sequences, then make them tensors\n",
        "        eng_seq = torch.LongTensor(eng_pipeline(eng))\n",
        "        fra_seq = torch.LongTensor(fra_pipeline(fra))\n",
        "\n",
        "        # append sequences to lists\n",
        "        eng_list.append(eng_seq)\n",
        "        fra_list.append(fra_seq)\n",
        "\n",
        "    # pad sequences to desired lengths\n",
        "    inp_tensor = pad_sequence(eng_list,batch_first=True)\n",
        "    targ_tensor = pad_sequence(fra_list,batch_first=True)\n",
        "\n",
        "    # move tensors to device\n",
        "    return inp_tensor.to(device), targ_tensor.to(device)\n",
        "\n",
        "BSZ = 128\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=BSZ,collate_fn=collate_batch,shuffle=True)\n",
        "valid_loader = DataLoader(valid_set,batch_size=BSZ,collate_fn=collate_batch,shuffle=False)"
      ],
      "metadata": {
        "id": "_1Hh7o3VeCXp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder-decoder model using LSTM\n",
        "\n",
        "Here we are going to use **teacher forcing** for training, which means the correct token of the target language is passed into the decoder, and then the decoder predicts the next token. If without teacher forcing, the previously decoder-predicted token is passed into the decoder as the current step input.\n",
        "\n",
        "Different from the keras notebook, where we had two instances of the decoder, here we only have one, because we'll make the decoder process one token at a time. That way, the same decoder instance will function properly during both training and prediction. Also, this makes it possible to stochastically impose teacher forcing to the model, because now we can make the algorithm randomly choose between output token from previous step or the true token of the current step, since the decoder processes one token at a time."
      ],
      "metadata": {
        "id": "E4jYqrL_aHc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "fq7Cnp4Lqspg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBED_DIM = 256\n",
        "HIDDEN_DIM = 512"
      ],
      "metadata": {
        "id": "AKTJfWibW5UF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,embed_dim,hidden_dim,lstm_layers=3,dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim  \n",
        "        self.lstm_layers = lstm_layers \n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_eng_size,embed_dim,padding_idx=0)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embed_dim,hidden_dim,lstm_layers,\n",
        "                            dropout=dropout,batch_first=True)\n",
        "        \n",
        "        \n",
        "    def forward(self,seq):\n",
        "        emb = self.embedding(seq)\n",
        "        lstm_out,(hidden,cell) = self.lstm(emb)\n",
        "        # size of h & c: (n layers, batch size, hidden dim)\n",
        "\n",
        "        return (hidden,cell)"
      ],
      "metadata": {
        "id": "y7H_cCAzV2kr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decoder processes one token at a time, rather than the whole sequence."
      ],
      "metadata": {
        "id": "nV-Dw2ctbgpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,embed_dim,hidden_dim,lstm_layers=3,dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm_layers = lstm_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_fra_size,embed_dim,padding_idx=0)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embed_dim,hidden_dim,lstm_layers,\n",
        "                            dropout=dropout,batch_first=True)\n",
        "        \n",
        "        self.fc_head = nn.Linear(hidden_dim,vocab_fra_size)\n",
        "\n",
        "    def forward(self,tok,hidden,cell):\n",
        "        \n",
        "        tok = tok.unsqueeze(1)\n",
        "        # tok: (batch size, 1)\n",
        "\n",
        "        emb = self.embedding(tok)\n",
        "        lstm_out,(hidden,cell) = self.lstm(emb,(hidden,cell))\n",
        "        # lstm_out: (batch size, 1, hidden dim)\n",
        "        # hidden & cell: (n layers, batch size, hidden dim)\n",
        "\n",
        "        pred = self.fc_head(lstm_out.squeeze(1))\n",
        "        # pred: (batch size, vocab size of target lang)\n",
        "\n",
        "        return (pred, hidden, cell)"
      ],
      "metadata": {
        "id": "7CbaIz5nZs6o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        assert encoder.hidden_dim == decoder.hidden_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.lstm_layers == decoder.lstm_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "\n",
        "    def forward(self,inp,trg,teacher_forcing_ratio=0.5):\n",
        "        # teacher forcing ratio: probability to use teacher forcing\n",
        "        bsz = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        # tensor to store output tokens from decoder later\n",
        "        outputs = torch.zeros(bsz,trg_len,vocab_fra_size).to(device)\n",
        "\n",
        "        # encode input sequence and get states\n",
        "        hidden, cell = self.encoder(inp)\n",
        "\n",
        "        # input to decoder: the start of sequence tokens\n",
        "        dec_in = trg[:,0]\n",
        "        \n",
        "        # for each time step\n",
        "        for t in range(1,trg_len):\n",
        "            # decoder outputs one token\n",
        "            output,hidden,cell = self.decoder(dec_in,hidden,cell)\n",
        "            outputs[:,t,:] = output\n",
        "\n",
        "            # decide if we use teacher forcing at this time step\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # get the token with the highest pred prob\n",
        "            top1 = output.argmax(1)\n",
        "\n",
        "            # if teacher forcing, use actual next token as next input token to decoder\n",
        "            # if not, use predicted token\n",
        "            dec_in = trg[:,t] if teacher_force else top1\n",
        "        \n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "mq4ccz34cFaO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(EMBED_DIM,HIDDEN_DIM)\n",
        "dec = Decoder(EMBED_DIM,HIDDEN_DIM)\n",
        "net = Seq2Seq(enc,dec).to(device)"
      ],
      "metadata": {
        "id": "u4pmDSoffLLA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `apply` method of our model `net`, to apply a function to every sub-module of `net`. For each module, we loop over all parameters and sample them from a uniform distribution."
      ],
      "metadata": {
        "id": "OicLUHMBfuoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model\n",
        "\n",
        "Just like the previous LSTM tutorial, we separately code functions for initializing weights, training, validation, and other supporting tasks to make the main training code concise. \n",
        "\n",
        "We also implement a basic early stopping algorithm that monitors the validation loss per epoch.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UBUmV0jHqvRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "net.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFvAA3N0flSq",
        "outputId": "825b5b94-f84d-4715-b229-fcc8f8aaffc4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(10000, 256, padding_idx=0)\n",
              "    (lstm): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.4)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(10000, 256, padding_idx=0)\n",
              "    (lstm): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.4)\n",
              "    (fc_head): Linear(in_features=512, out_features=10000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(net):,} trainable parameters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RGktexygAIv",
        "outputId": "6bbcd384-6057-4cc9-8d81-5e9e31af6c69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 21,808,912 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, dataloader, optimizer, criterion, clip, force=1):\n",
        "    net.train()\n",
        "    loss_list = []\n",
        "    log_interval = 250\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (inp_seq, targ_seq) in enumerate(dataloader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass \n",
        "        output = net(inp_seq,targ_seq,force)\n",
        "        # output: (batch size, targ len, targ vocab size)\n",
        "        # targ_seq: (batch size, targ len)\n",
        "\n",
        "        # get rid of the sos tokens\n",
        "        # reshape output and target sequence for loss calculation\n",
        "        output = output[:,1:,:].reshape(-1,vocab_fra_size)\n",
        "        targ_seq = targ_seq[:,1:].reshape(-1)\n",
        "        # output: (batch size * (targ len-1), targ vocab size)\n",
        "        # targ_seq: (batch size * (targ len-1),)\n",
        "\n",
        "        # compute loss\n",
        "        loss = criterion(output, targ_seq)\n",
        "        loss.backward()\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # clip gradients\n",
        "        nn.utils.clip_grad_norm_(net.parameters(),clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            last_few_losses = np.mean(np.array(loss_list))\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| loss {:.6f} '.format(epoch, idx, len(dataloader), \n",
        "                                              last_few_losses))\n",
        "            total_acc, total_count = 0, 0\n",
        "            loss_list = []\n",
        "            start_time = time.time()"
      ],
      "metadata": {
        "id": "ETVLhpdl3ceI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, dataloader, criterion):\n",
        "    net.eval()\n",
        "    loss_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inp_seq, targ_seq) in enumerate(dataloader):\n",
        "                      \n",
        "            # turn off teacher forcing\n",
        "            output = net(inp_seq,targ_seq,teacher_forcing_ratio=0)\n",
        "\n",
        "            output = output[:,1:,:].reshape(-1,vocab_fra_size)\n",
        "            targ_seq = targ_seq[:,1:].reshape(-1)\n",
        "            loss = criterion(output, targ_seq)\n",
        "            loss_list.append(loss.item())\n",
        "    \n",
        "    # return validation loss \n",
        "    return np.mean(np.array(loss_list))"
      ],
      "metadata": {
        "id": "74pIrvcJj7rR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "KMsJI0jKkwfJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping class for monitoring valid loss\n",
        "\n",
        "class EarlyStop:\n",
        "    def __init__(self,net_save_path,patience=2,delta=1e-3):\n",
        "        self.best_loss = math.inf # initialize to +infty\n",
        "        self.patience = patience  # how many bad epochs we tolerate\n",
        "        self.count = 0       # count of bad epochs\n",
        "        self.delta = delta   # threshold to determine significance of decrease in valid loss\n",
        "        self.path = net_save_path\n",
        "        self.stop = False\n",
        "\n",
        "    def step(self,valid_loss,net):\n",
        "        '''Decides whether to stop training according to the current valid loss,\n",
        "           the best valid loss, and the count of bad epochs'''\n",
        "\n",
        "        # if stop condition satisfied already, skip \n",
        "        if self.stop == True:\n",
        "            return \n",
        "\n",
        "        # if valid loss decreases (significantly w.r.t. delta)\n",
        "        if (valid_loss<self.best_loss) and (math.fabs(valid_loss-self.best_loss)>self.delta):\n",
        "            # update best valid loss\n",
        "            self.best_loss = valid_loss\n",
        "            # reset count of bad epochs\n",
        "            self.count = 0\n",
        "            # save current model as best model\n",
        "            torch.save(net.state_dict(),self.path)\n",
        "        else:\n",
        "            # count of bad epochs +1, i.e. the current epoch makes the model worse\n",
        "            self.count += 1\n",
        "        \n",
        "        # if count of bad epochs exceeds patience\n",
        "        if self.count >= self.patience:\n",
        "            # status updated to stop\n",
        "            self.stop = True\n",
        "\n",
        "    def get_best_model(self,net):\n",
        "        net.load_state_dict(torch.load(self.path))\n",
        "    "
      ],
      "metadata": {
        "id": "bvKdpEfxNCxj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 5e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# stochastic gradient descent as optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=LR)\n",
        "\n",
        "# early stopping\n",
        "es = EarlyStop('seq2seq_eng_fra.pt')"
      ],
      "metadata": {
        "id": "zME8sfCnS7Y-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "CLIP = 1\n",
        "TEACHER_FORCE = 0.8\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # record starting time of the epoch\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    train(net, train_loader, optimizer, criterion, CLIP, TEACHER_FORCE)\n",
        "    valid_loss = evaluate(net, valid_loader, criterion)\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(epoch_start_time,epoch_end_time)\n",
        "\n",
        "    # update early stopper\n",
        "    es.step(valid_loss, net)\n",
        "\n",
        "    print('-' * 90)\n",
        "    print('| end of epoch {:3d} | time: {:2d}m {:2d}s '\n",
        "          '| valid loss {:.6f} '.format(epoch,\n",
        "                                        epoch_mins, epoch_secs,\n",
        "                                        valid_loss))\n",
        "    print('-' * 90)\n",
        "\n",
        "    # check condition of early stop\n",
        "    if es.stop == True:\n",
        "        print('\\nearly stopped!')\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEKdymmVTQhw",
        "outputId": "a7e9c2cc-b82f-4427-ea33-eeadfb684fb3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   250/ 1716 batches | loss 2.197274 \n",
            "| epoch   1 |   500/ 1716 batches | loss 1.938137 \n",
            "| epoch   1 |   750/ 1716 batches | loss 1.863558 \n",
            "| epoch   1 |  1000/ 1716 batches | loss 1.790545 \n",
            "| epoch   1 |  1250/ 1716 batches | loss 1.758188 \n",
            "| epoch   1 |  1500/ 1716 batches | loss 1.689692 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 22m 28s | valid loss 2.274353 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   2 |   250/ 1716 batches | loss 1.647736 \n",
            "| epoch   2 |   500/ 1716 batches | loss 1.625399 \n",
            "| epoch   2 |   750/ 1716 batches | loss 1.618799 \n",
            "| epoch   2 |  1000/ 1716 batches | loss 1.601477 \n",
            "| epoch   2 |  1250/ 1716 batches | loss 1.582836 \n",
            "| epoch   2 |  1500/ 1716 batches | loss 1.561684 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 22m 32s | valid loss 2.160695 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   3 |   250/ 1716 batches | loss 1.527300 \n",
            "| epoch   3 |   500/ 1716 batches | loss 1.508903 \n",
            "| epoch   3 |   750/ 1716 batches | loss 1.504141 \n",
            "| epoch   3 |  1000/ 1716 batches | loss 1.513061 \n",
            "| epoch   3 |  1250/ 1716 batches | loss 1.480571 \n",
            "| epoch   3 |  1500/ 1716 batches | loss 1.481932 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 22m 30s | valid loss 2.069074 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   4 |   250/ 1716 batches | loss 1.452408 \n",
            "| epoch   4 |   500/ 1716 batches | loss 1.423015 \n",
            "| epoch   4 |   750/ 1716 batches | loss 1.418949 \n",
            "| epoch   4 |  1000/ 1716 batches | loss 1.422337 \n",
            "| epoch   4 |  1250/ 1716 batches | loss 1.406192 \n",
            "| epoch   4 |  1500/ 1716 batches | loss 1.411200 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 22m 39s | valid loss 1.965086 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   5 |   250/ 1716 batches | loss 1.377882 \n",
            "| epoch   5 |   500/ 1716 batches | loss 1.352918 \n",
            "| epoch   5 |   750/ 1716 batches | loss 1.342935 \n",
            "| epoch   5 |  1000/ 1716 batches | loss 1.357273 \n",
            "| epoch   5 |  1250/ 1716 batches | loss 1.358820 \n",
            "| epoch   5 |  1500/ 1716 batches | loss 1.329796 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 22m 50s | valid loss 1.996727 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   6 |   250/ 1716 batches | loss 1.304275 \n",
            "| epoch   6 |   500/ 1716 batches | loss 1.292086 \n",
            "| epoch   6 |   750/ 1716 batches | loss 1.306946 \n",
            "| epoch   6 |  1000/ 1716 batches | loss 1.304547 \n",
            "| epoch   6 |  1250/ 1716 batches | loss 1.275656 \n",
            "| epoch   6 |  1500/ 1716 batches | loss 1.268511 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 22m 50s | valid loss 1.916723 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   7 |   250/ 1716 batches | loss 1.259938 \n",
            "| epoch   7 |   500/ 1716 batches | loss 1.237719 \n",
            "| epoch   7 |   750/ 1716 batches | loss 1.230115 \n",
            "| epoch   7 |  1000/ 1716 batches | loss 1.253581 \n",
            "| epoch   7 |  1250/ 1716 batches | loss 1.247700 \n",
            "| epoch   7 |  1500/ 1716 batches | loss 1.231684 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 22m 45s | valid loss 1.940302 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   8 |   250/ 1716 batches | loss 1.215456 \n",
            "| epoch   8 |   500/ 1716 batches | loss 1.195995 \n",
            "| epoch   8 |   750/ 1716 batches | loss 1.199578 \n",
            "| epoch   8 |  1000/ 1716 batches | loss 1.196906 \n",
            "| epoch   8 |  1250/ 1716 batches | loss 1.190687 \n",
            "| epoch   8 |  1500/ 1716 batches | loss 1.205324 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 22m 51s | valid loss 1.913271 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch   9 |   250/ 1716 batches | loss 1.171428 \n",
            "| epoch   9 |   500/ 1716 batches | loss 1.153373 \n",
            "| epoch   9 |   750/ 1716 batches | loss 1.158536 \n",
            "| epoch   9 |  1000/ 1716 batches | loss 1.172553 \n",
            "| epoch   9 |  1250/ 1716 batches | loss 1.160367 \n",
            "| epoch   9 |  1500/ 1716 batches | loss 1.150583 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 22m 52s | valid loss 1.887656 \n",
            "------------------------------------------------------------------------------------------\n",
            "| epoch  10 |   250/ 1716 batches | loss 1.138155 \n",
            "| epoch  10 |   500/ 1716 batches | loss 1.134157 \n",
            "| epoch  10 |   750/ 1716 batches | loss 1.151141 \n",
            "| epoch  10 |  1000/ 1716 batches | loss 1.136208 \n",
            "| epoch  10 |  1250/ 1716 batches | loss 1.129259 \n",
            "| epoch  10 |  1500/ 1716 batches | loss 1.138948 \n",
            "------------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 22m 49s | valid loss 1.896601 \n",
            "------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions\n"
      ],
      "metadata": {
        "id": "-gvx_Rne6oy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Best Model"
      ],
      "metadata": {
        "id": "X6O4uv3nF9Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(EMBED_DIM,HIDDEN_DIM)\n",
        "dec = Decoder(EMBED_DIM,HIDDEN_DIM)\n",
        "net = Seq2Seq(enc,dec).to(device)\n",
        "\n",
        "#net.load_state_dict(torch.load('./seq2seq_eng_fra.pt'))\n",
        "es.get_best_model(net)"
      ],
      "metadata": {
        "id": "6GiXFYnoF-TC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction setup\n",
        "\n"
      ],
      "metadata": {
        "id": "1ML6lYyn6sN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_with_raw(batch):\n",
        "\n",
        "    eng_list, fra_list = [], []\n",
        "    eng_text, fra_text = [], []\n",
        "\n",
        "    for pair in batch:\n",
        "        assert len(pair['eng']) == 1, 'length of one value in dict more than 1!'\n",
        "        \n",
        "        eng = pair['eng'][0]\n",
        "        fra = pair['fra'][0]\n",
        "        eng_text.append(eng)\n",
        "        fra_text.append(fra)\n",
        "        \n",
        "        # convert text to sequences, then make them tensors\n",
        "        eng_seq = torch.LongTensor(eng_pipeline(eng))\n",
        "        fra_seq = torch.LongTensor(fra_pipeline(fra))\n",
        "\n",
        "        # append sequences to lists\n",
        "        eng_list.append(eng_seq)\n",
        "        fra_list.append(fra_seq)\n",
        "\n",
        "    # pad sequences to desired lengths\n",
        "    inp_tensor = pad_sequence(eng_list,batch_first=True)\n",
        "    targ_tensor = pad_sequence(fra_list,batch_first=True)\n",
        "\n",
        "    # output tensors as well as original text\n",
        "    return inp_tensor.to(device), targ_tensor.to(device), eng_text, fra_text\n",
        "\n",
        "def evaluate_and_print(net, dataloader, criterion):\n",
        "    net.eval()\n",
        "    loss_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (inp_seq, targ_seq, eng_text, fra_text) in enumerate(dataloader):\n",
        "            # turn off teacher forcing\n",
        "            output = net(inp_seq,targ_seq,teacher_forcing_ratio=0)\n",
        "            # output: (batch size, targ len, vocab size of targ)\n",
        "\n",
        "            output_reshaped = output[:,1:,:].reshape(-1,vocab_fra_size)\n",
        "            targ_seq_reshaped = targ_seq[:,1:].reshape(-1)\n",
        "            loss = criterion(output_reshaped, targ_seq_reshaped)\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "            preds = torch.argmax(output[:,1:,:],2)\n",
        "            first_seq_pred = preds[0,:].tolist()\n",
        "\n",
        "            # print out the first example of the batch\n",
        "            print('English:', ' '.join(eng_text[0].split()[1:-1]))\n",
        "            print('Original French:', ' '.join(fra_text[0].split()[1:-1]))\n",
        "            print('Predicted French:', fra_tokenizer.decode(first_seq_pred))\n",
        "            print()\n",
        "    \n",
        "    # return avg validation loss \n",
        "    return np.mean(np.array(loss_list))"
      ],
      "metadata": {
        "id": "m47RqYRCxecC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = TextDataset('test_df.csv')\n",
        "test_loader = DataLoader(test_set,batch_size=BSZ,collate_fn=collate_batch_with_raw,\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "0k4aV1cfw3LX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions on the test set"
      ],
      "metadata": {
        "id": "HVm4NfoAZ3gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate_and_print(net,test_loader,criterion).item()\n",
        "print(\"average loss in test set:\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywLaZoD-xLYe",
        "outputId": "f83bd4af-9783-43b7-d17a-83d0ed706dfa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: when was in my i saw my very first psychotherapy client\n",
            "Original French: quand avais la vingtaine ai vu mes tout premiers clients comme psychotherapeute\n",
            "Predicted French: quand je suis arrive mon premier mon premier groupe de mon pere\n",
            "\n",
            "English: throughout the history of computers we ve been striving to shorten the gap between us and digital information the gap between our physical world and the world in the screen where our imagination can go wild\n",
            "Original French: tout au long de histoire de informatique nous avons tache de combler le fosse entre nous et le monde numerique ecart entre notre monde physique et le monde derriere notre ecran ou notre imagination peut epanouir\n",
            "Predicted French: au cours de nos experiences nous avons commence nous nous avons ##ons la vie de notre vie et notre monde et la de la vie de la planete et la musique de la nature et la nature que nous pouvons nous faire\n",
            "\n",
            "English: we forget how harsh his vision was\n",
            "Original French: on oublie quel point sa vision etait severe\n",
            "Predicted French: nous lui disons le son de la vie\n",
            "\n",
            "English: and then the garbage itself is full of hazards that often fly back out of the truck and do terrible harm\n",
            "Original French: et puis les ordures elles meme sont pleines de dangers qui souvent ressortent du camion et font terriblement mal\n",
            "Predicted French: et puis les fourmis sont ##nt ##s et les les ##s sont en fait de la et de la et ils sont tres tres dangereux\n",
            "\n",
            "English: so looked at the stage manager and m like excuse me can have another chair\n",
            "Original French: j ai regarde la regisseuse de plateau et je lui ai dit excusez moi est ce que je pourrais avoir un autre fauteuil\n",
            "Predicted French: j ai donc regarde le chef de la et je me suis dit je vais etre un peu\n",
            "\n",
            "English: it called the united states memory championship\n",
            "Original French: elle appelle le championnat de memoire des etats unis\n",
            "Predicted French: il appelle le la de la plus de plus de\n",
            "\n",
            "English: it make thought maybe nice epilogue to all my research\n",
            "Original French: j en aurais peut etre fait un bel epilogue toutes mes recherches\n",
            "Predicted French: il me semble que je me suis un peu de pour moi\n",
            "\n",
            "English: and it where all the neighbors they can go up and socialize and do activities such as having two kilometer run in the morning jumping from one building to another\n",
            "Original French: et est la ou tous les voisins peuvent se reunir et faire des activites comme une course de deux kilometres de bon matin en passant un batiment l autre\n",
            "Predicted French: et est la que les bebes et les gens peuvent aller dans le monde et ils peuvent utiliser un nouveau temps de la de la taille de la\n",
            "\n",
            "English: compare this to with the wizard of oz\n",
            "Original French: comparons ca au magicien oz de\n",
            "Predicted French: comparez ca avec le de la de la\n",
            "\n",
            "English: he began renting out motorbikes to local residents who couldn normally afford them\n",
            "Original French: il commence louer ces motos des residents locaux qui ne pouvaient en temps normal se le permettre\n",
            "Predicted French: il commence par les les de la les les gens qui ne pouvaient pas les faire\n",
            "\n",
            "English: the sun is coming up above the horizon sunrise\n",
            "Original French: le soleil se leve au dessus de horizon aube\n",
            "Predicted French: le soleil est le soleil de la lumiere de la\n",
            "\n",
            "average loss in test set: 1.9389947327700527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "LMT1zDbRmH0v"
      }
    }
  ]
}